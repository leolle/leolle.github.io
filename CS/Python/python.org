#+SETUPFILE: ../../configOrg/level2.org
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline author:t c:nil
#+OPTIONS: creator:nil d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+OPTIONS: title:t toc:t todo:t |:t
#+TITLES: python2
#+DATE: <2017-05-24 Wed>
#+AUTHORS: weiwu
#+EMAIL: victor.wuv@gmail.com
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode 8.3.4)

[[http://www.pythondoc.com/pythontutorial3/][source]]
* Introduction
* Built-in Functions

** Function
*** print
****  output formatting:
To use formatted string literals, begin a string with f or F before the opening quotation mark or triple quotation mark. Inside this string, you can write a Python expression between { and } characters that can refer to variables or literal values.

#+BEGIN_SRC python
>>> year = 2016
>>> event = 'Referendum'
>>> f'Results of the {year} {event}'
'Results of the 2016 Referendum'

#+END_SRC
- The str.format() method
#+BEGIN_SRC python
>>> yes_votes = 42_572_654
>>> no_votes = 43_132_495
>>> percentage = yes_votes / (yes_votes + no_votes)
>>> '{:-9} YES votes  {:2.2%}'.format(yes_votes, percentage)
' 42572654 YES votes  49.67%'

#+END_SRC
- Formatted String Literals
#+BEGIN_SRC python
>>> table = {'Sjoerd': 4127, 'Jack': 4098, 'Dcab': 7678}
>>> for name, phone in table.items():
...     print(f'{name:10} ==> {phone:10d}')
...
Sjoerd     ==>       4127
Jack       ==>       4098
Dcab       ==>       7678

>>> animals = 'eels'
>>> print(f'My hovercraft is full of {animals}.')
My hovercraft is full of eels.
>>> print(f'My hovercraft is full of {animals!r}.')
My hovercraft is full of 'eels'.


#+END_SRC
- String format() method:
#+BEGIN_SRC python
>>> print('We are the {} who say "{}!"'.format('knights', 'Ni'))
We are the knights who say "Ni!"

>>> print('{0} and {1}'.format('spam', 'eggs'))
spam and eggs
>>> print('{1} and {0}'.format('spam', 'eggs'))
eggs and spam

>>> print('This {food} is {adjective}.'.format(
...       food='spam', adjective='absolutely horrible'))
This spam is absolutely horrible.

>>> print('The story of {0}, {1}, and {other}.'.format('Bill', 'Manfred',
                                                       other='Georg'))
The story of Bill, Manfred, and Georg.

>>> table = {'Sjoerd': 4127, 'Jack': 4098, 'Dcab': 8637678}
>>> print('Jack: {0[Jack]:d}; Sjoerd: {0[Sjoerd]:d}; '
...       'Dcab: {0[Dcab]:d}'.format(table))
Jack: 4098; Sjoerd: 4127; Dcab: 8637678

>>> table = {'Sjoerd': 4127, 'Jack': 4098, 'Dcab': 8637678}
>>> print('Jack: {Jack:d}; Sjoerd: {Sjoerd:d}; Dcab: {Dcab:d}'.format(**table))
Jack: 4098; Sjoerd: 4127; Dcab: 8637678

#+END_SRC
- print into file:
#+BEGIN_SRC python
#  python 3.x syntax. 
print(args, file=f1) 
# For python 2.x use 
print >> f1, args.

#+END_SRC
- pythonic returning values:
#+BEGIN_SRC python
def foo():
    return 'a' if value is True else 'b'
#+END_SRC
- function parameter
  - pass the parameters boo(a=1,b=2) won’t change the value of the parameters themselves. the sequence of the parameters are certain, you can’t change it.

- if the input argument is un-mutable,函数中改变形参值不会改变原值。
if the input is mutable, operate on the input like append operation will change the input argument.

- 11076976a, b = b, a + b # 相当于：
#+begin_src python
t = (b, a + b) # t是一个tuple
table_resulta = t[0]
b = t[1]
#+end_src
*** normal argument, args, kwargs
*args and **kwargs allow you to pass a variable number of arguments to a function. 
- *args:
#+BEGIN_SRC python
def test_var_args(f_arg, *argv):
    print "first normal arg:", f_arg
    for arg in argv:
        print "another arg through *argv :", arg

test_var_args('yasoob','python','eggs','test')

#+END_SRC
- **kwargs:
#+BEGIN_SRC python
>>> kwargs = {"arg3": 3, "arg2": "two","arg1":5}
>>> test_args_kwargs(**kwargs)
arg1: 5
arg2: two
arg3: 3

#+END_SRC
** trouble shooting
- linux python FileNotFoundEr
ror: [Errno 2] No such file or directory:

try to use absolute path instead of relative path to read a file.

- HDF5
pip install tables

** Decorator
Decorator is way to dynamically add some new behavior to some objects. We achieve the same in Python by using closuhttp://cnki.cn-ki.net/KCMS/detail/detail.aspx?QueryID=1&CurRec=1&recid=&filename=1019008654.nh&dbname=CDFDTEMP&dbcode=CDFD&yx=&pr=&URLID=&forcenew=nores.

In the example we will create a simple example which will print some statement before and after the execution of a function.

#+BEGIN_SRC python
>>> def my_decorator(func):
...     def wrapper(*args, **kwargs):
...         print("Before call")
...         result = func(*args, **kwargs)
...         print("After call")
...         return result
...     return wrapper
...
>>> @my_decorator
... def add(a, b):
...     "Our add function"
...     return a + b
...
>>> add(1, 3)
Before call
After call
4

#+END_SRC
Common examples for decorators are classmethod() and staticmethod().
*** classmethod(function)
Return a class method for function.

A class method receives the class as implicit first argument, just like an instance method receives the instance. To declare a class method, use this idiom:

class C(object):
    @classmethod
    def f(cls, arg1, arg2, ...):
        ...
The @classmethod form is a function decorator – see the description of function definitions in Function definitions for details.

It can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class. If a class method is called for a derived class, the derived class object is passed as the implied first argument.

Class methods are different than C++ or Java static methods. If you want those, see staticmethod() in this section.

For more information on class methods, consult the documentation on the standard type hierarchy in The standard type hierarchy.
*** staticmethod(function)
Return a static method for function.

A static method does not receive an implicit first argument. To declare a static method, use this idiom:

class C(object):
    @staticmethod
    def f(arg1, arg2, ...):
        ...
The @staticmethod form is a function decorator – see the description of function definitions in Function definitions for details.

It can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class.

Static methods in Python are similar to those found in Java or C++. Also see classmethod() for a variant that is useful for creating alternate class constructors.

For more information on static methods, consult the documentation on the standard type hierarchy in The standard type hierarchy.


** Closures
Closures are nothing but functions that are returned by another function. We use closures to remove code duplication. In the following example we create a simple closure for adding numbers.
#+BEGIN_SRC python
>>> def add_number(num):
...     def adder(number):
...         'adder is a closure'
...         return num + number
...     return adder
...
>>> a_10 = add_number(10)
>>> a_10(21)
31
>>> a_10(34)
44
>>> a_5 = add_number(5)
>>> a_5(3)
8

#+END_SRC
** iterable
An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict and file and objects of any classes you define with an __iter__() or __getitem__() method. Iterables can be used in a for loop and in many other places where a sequence is needed (zip(), map(), …). When an iterable object is passed as an argument to the built-in function iter(), it returns an iterator for the object. This iterator is good for one pass over the set of values. When using iterables, it is usually not necessary to call iter() or deal with iterator objects yourself. The for statement does that automatically for you, creating a temporary unnamed variable to hold the iterator for the duration of the loop. See also iterator, sequence, and generator.

- check if an object is iterable
#+BEGIN_SRC python
>>> from collections import Iterable
>>> l = [1, 2, 3, 4]
>>> isinstance(l, Iterable)
True

#+END_SRC
** iterator
An object representing a stream of data. Repeated calls to the iterator’s next() method return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its next() method just raise StopIteration again. Iterators are required to have an __iter__() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container.
** generator
A function which returns an iterator. It looks like a normal function except that it contains yield statements for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function. Each yield temporarily suspends processing, remembering the location execution state (including local variables and pending try-statements). When the generator resumes, it picks-up where it left-off (in contrast to functions which start fresh on every invocation).
** generator expression
An expression that returns an iterator. It looks like a normal expression followed by a for expression defining a loop variable, range, and an optional if expression. The combined expression generates values for an enclosing function:
#+BEGIN_SRC python
>>> sum(i*i for i in range(10))         # sum of squares 0, 1, 4, ... 81
285

#+END_SRC



* Built-in Types
** Truth Value Testing
** Boolean Operations — and, or, not
- The ^ symbol
  - The ^ symbol is for the bitwise ‘xor’ operation, but in Python, the exponent operator symbol is **.
- the minimum value between nan and infinity is infinity.
min(np.nan, np.inf) = np.inf

- eval
eval the value of a variable name from string.
#+BEGIN_SRC python
text = '{'a':1}'
eval(text) # will turn text from a string object into a dictionary object
#+END_SRC
** Comparisons
** Numeric Types — int, float, complex
** Iterator Types
- xrange vs range:
there's no xrange in python 3.
- Finding the index of an item given a list:
#+BEGIN_SRC python
>>> ["foo", "bar", "baz"].index("bar")
1
#+END_SRC
- access index and value looping a list:
#+BEGIN_SRC python
for idx, val in enumerate(list):
    print(idx, val)

#+END_SRC
- iterable vs iterator vs generator:
The difference between iterables and generators: once you’ve burned through a generator once, you’re done, no more data.
#+BEGIN_SRC python
generator = (word + '!' for word in 'baby let me iterate ya'.split())
# The generator object is now created, ready to be iterated over.
# No exclamation marks added yet at this point.

for val in generator: # real processing happens here, during iteration
    print val,
baby! let! me! iterate! ya!

for val in generator:
    print val,
# Nothing printed! No more data, generator stream already exhausted above.
#+END_SRC
an iterable creates a new iterator every time it’s looped over (technically, every time iterable.__iter__() is called, such as when Python hits a “for” loop):
#+BEGIN_SRC python
class BeyonceIterable(object):
    def __iter__(self):
        """
        The iterable interface: return an iterator from __iter__().

        Every generator is an iterator implicitly (but not vice versa!),
        so implementing `__iter__` as a generator is the easiest way
        to create streamed iterables.

        """
        for word in 'baby let me iterate ya'.split():
            yield word + '!'  # uses yield => __iter__ is a generator

iterable = BeyonceIterable()

for val in iterable:  # iterator created here
    print val,
baby! let! me! iterate! ya!

for val in iterable:  # another iterator created here
    print val,
baby! let! me! iterate! ya!
#+END_SRC

- magic method __iter__:
Iterators are everywhere in Python. They are elegantly implemented within for loops, comprehensions, generators etc. but hidden in plain sight.

Iterator in Python is simply an object that can be iterated upon. An object which will return data, one element at a time.

Technically speaking, Python iterator object must implement two special methods, __iter__() and __next__(), collectively called the iterator protocol.

An object is called iterable if we can get an iterator from it. Most of built-in containers in Python like: list, tuple, string etc. are iterables.

The iter() function (which in turn calls the __iter__() method) returns an iterator from them.

- Iterating Through an Iterator in Python
use the $next()$ function to manually iterate through all the items of an iterator.
#+BEGIN_SRC python
# define a list
my_list = [4, 7, 0, 3]

# get an iterator using iter()
my_iter = iter(my_list)

## iterate through it using next()

#prints 4
print(next(my_iter))

#prints 7
print(next(my_iter))

## next(obj) is same as obj.__next__()

#prints 0
print(my_iter.__next__())

#prints 3
print(my_iter.__next__())

## This will raise error, no items left
next(my_iter)
#+END_SRC
A more elegant way of automatically iterating is by using the for loop. Using this, we can iterate over any object that can return an iterator, for example list, string, file etc.
#+BEGIN_SRC python
for element in my_list:
    print(element)
#+END_SRC
- How for loop actually works?
#+BEGIN_SRC python
for element in iterable:
    # do something with element
# Is actually implemented as.

# create an iterator object from that iterable
iter_obj = iter(iterable)

# infinite loop
while True:
    try:
        # get the next item
        element = next(iter_obj)
        # do something with element
    except StopIteration:
        # if StopIteration is raised, break from loop
        break

#+END_SRC
- example:
#+BEGIN_SRC python
class PowTwo:
    """Class to implement an iterator
    of powers of two"""

    def __init__(self, max = 0):
        self.max = max

    def __iter__(self):
        self.n = 0
        return self

    def __next__(self):
        if self.n <= self.max:
            result = 2 ** self.n
            self.n += 1
            return result
        else:
            raise StopIteration

# create an iterator and iterate through it as follows.

>>> a = PowTwo(4)
>>> i = iter(a)
>>> next(i)
1
>>> next(i)
2
>>> next(i)
4
>>> next(i)
8
>>> next(i)
16
>>> next(i)
Traceback (most recent call last):
...
StopIteration

# use a for loop to iterate over our iterator class.

>>> for i in PowTwo(5):
...     print(i)
#+END_SRC
** Sequence Types — list, tuple, range
- is list equal:
#+BEGIN_SRC python
a = [1,2,3]
b = [3,2,1]
a.sort()
b.sort()
a == b
#+END_SRC
- Unique value from list of lists:
#+BEGIN_SRC python
testdata = [list(x) for x in set(tuple(x) for x in testdata)]

#+END_SRC

- nested list comprehension:
#+BEGIN_SRC python
[x+y for x in [1,2,3] for y in [4,5,6]]
# equal to
res =[]
for x in [1,2,3]:
    for y in [4,5,6]:
        res.append(x+y)
[y+1 for x in [[1,2],[2,2],[3,2]] for y in x]

# equal to
res =[]
for x in [[1,2],[2,2],[3,2]]:
    for y in x:
        res.append(1+y)
#+END_SRC
- remove value in a list:
#+BEGIN_SRC python
list.remove('value')
#+END_SRC
- tuple vs set
A set is a slightly different concept from a list or a tuple. A set, in Python, is just like the mathematical set. It does not hold duplicate values, and is unordered. However, it is not immutable unlike a tuple.Jan 9, 2018

- combine list of lists into one list, join list of lists
#+BEGIN_SRC python
import itertools
a = [["a","b"], ["c"]]
print list(itertools.chain.from_iterable(a))
# or
lambda: (lambda b: map(b.extend, big_list))([])
#+END_SRC
- find difference of two lists:
#+begin_src python
a = [1,2,3,2,1,5,6,5,5,5]
import collections
print [item for item, count in collections.Counter(a).items() if count > 1]
#+end_src

- 列表生成式list comprehension
#+begin_src python
[a.lower() for a in x=['Hello', 'World', 18, 'Apple', None] if isinstance(a,str)]
#+end_src

- read file to a list:
#+begin_src python
with open(r'y:\codes\data\smart_beta_etf_list.txt', 'rb') as f:
etf_list = f.readlines()
etf_list = [x.strip() for x in etf_list]
# you may also want to remove whitespace characters like `\n` at the end of each line
#+end_src

- save a list to a file:
#+begin_src python
thefile = open('test.txt', 'w')
import pickle

with open('outfile', 'wb') as fp:
    pickle.dump(itemlist, fp)
# To read it back:

with open ('outfile', 'rb') as fp:
    itemlist = pickle.load(fp)
#+end_src
- save a list of Chinese string to a file:
#+BEGIN_SRC python
values = [u'股市']
import codecs
with codecs.open("file.txt", "w", encoding="utf-8") as d:
    d.write(str(x0))
#+END_SRC
- for item in the list:
#+begin_src python
thefile.write("%s\n" % item)
#+end_src

- replace comma as next line (enter):
choose extend mode: replace ',' as \r\n

- split strings by space delimiter from reverse:
#+begin_src python
text.rsplit(' ', 1)[0]
#+end_src

- split strings by space delimiter from beginning:
#+begin_src python
text.split(' ', 1)[0]
>>>a.split('.',1)
['alvy','test.txt']
后面多了一个参数1，以第一个'.'分界，分成两个字符串，组成一个list
>>>a.rsplit('.',1)
['alvy.test','txt']
现在是rsplit函数，从右边第一个'.'分界，分成两个字符串，组成一个list
#+end_src
- split by comma:
#+BEGIN_SRC python
string.split(",")
#+END_SRC
- split by multiple delimiter:
#+BEGIN_SRC python
import re
re.split('; |, |\*|\n',str)
#+END_SRC
** 生成器generator
通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。
而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。
要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：
如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值：
next(g)
这里，最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。
而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。

#+begin_src python
def odd():
    print('step 1')

    yield 1
    print('step 2')
    yield(3)
    print('step 3')
    yield(5)
>>> o = odd()
>>> next(o)
step 1
1
>>> next(o)
step 2
3
>>> next(o)
step 3
5
>>> next(o)
Traceback (most recent call last):

  File "<stdin>", line 1, in <module>
StopIteration
#+end_src
A Generator is an Iterator

A function with yield in it is still a function, that, when called, returns an instance of a generator object:
#+BEGIN_SRC python
def a_function():
    "when called, returns generator object"
    yield

#+END_SRC
A generator expression also *returns a generator*:
#+BEGIN_SRC python
a_generator = (i for i in range(0))

#+END_SRC

A Generator is an Iterator

An Iterator is an Iterable

Iterators require a next or __next__ method

*** loop
- loop with batches:
#+BEGIN_SRC python
for i in tqdm(range(0, len(category), batch_size)):
    re_batch = {}
    for j in range(batch_size):
        re_batch[j] = wiki_category_re.search(category, last_span)
        if re_batch[j] is not None:
            last_span = re_batch[j].span()[1]
    upload_cat_node(re_batch)
#+END_SRC
- don't care the interator sequence:
#+BEGIN_SRC python
for _ in range(10):
    print(_)
#+END_SRC

- fetch several pairs from a dictionary:
#+BEGIN_SRC python
from itertools import islice

def take(n, iterable):
    "Return first n items of the iterable as a list"
    return list(islice(iterable, n))

n_items = take(3, dict_df_ret.items())
n_items

# or
list(islice(dictionary.items(), 3))
#+END_SRC

- iterate key and value in a dictionary:
#+begin_src python
# python 2
for index, value in dict.iteritems():
# python 3
for index, value in dict.items():
    print index, value
#+end_src
- iterate keys in a dictionary:
#+begin_src python
for k in dict:
#+end_src

- iterate a row in pandas dataframe:
#+begin_src python
DataFrame.iterrows():
return generator.
>>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])
>>> row = next(df.iterrows())[1]
>>> row
int      1.0
float    1.5
Name: 0, dtype: float64
>>> print(row['int'].dtype)
float64
>>> print(df['int'].dtype)
int64
#+end_src

- To preserve dtypes while iterating over the rows, it is better to use itertuples()
  - which returns tuples of the values and which is generally faster as iterrows.
** Text Sequence Type — str
** Binary Sequence Types — bytes, bytearray, memoryview
** Set Types — set, frozenset
- access an element in a set.
#+BEGIN_SRC python
a=set([1,2,3])
element = a.pop(0)

list(a)[0]
#+END_SRC

#+BEGIN_SRC python
from random import sample

def ForLoop(s):
    for e in s:
        break
    return e

def IterNext(s):
    return next(iter(s))

def ListIndex(s):
    return list(s)[0]

def PopAdd(s):
    e = s.pop()
    s.add(e)
    return e

def RandomSample(s):
    return sample(s, 1)

def SetUnpacking(s):
    e, *_ = s
    return e

from simple_benchmark import benchmark

b = benchmark([ForLoop, IterNext, ListIndex, PopAdd, RandomSample, SetUnpacking],
              {2**i: set(range(2**i)) for i in range(1, 20)},
              argument_name='set size',
              function_aliases={first: 'First'})

b.plot()
#+END_SRC
** Mapping Types — dict
- concat two dictionary:
#+BEGIN_SRC python
dict1.update(dict2)
#+END_SRC
- dump dictionary into pickle:
#+BEGIN_SRC python
with open('./data/disease.pkl', 'wb') as f:
    pickle.dump(dict_intravenous_thrombolysis, f)
#+END_SRC
- dump dictionary into json:
#+BEGIN_SRC python
import json
with open('multiple_paths.json', 'w', encoding='utf-8') as fp:
    js_obj = json.dumps(filtered_dict)
    fp.write(js_obj)
#+END_SRC
- get key from value:
#+BEGIN_SRC python
for name, age in word2id.items():    # for name, age in list.items():  (for Python 3.x)
    if age == 16116:
        print(name)

# or
mydict = {'george':16,'amber':19}
print(list(mydict.keys())[list(mydict.values()).index(16)]) # Prints george

print(list(word2id.keys())[list(word2id.values()).index(16116)]) # Prints
#+END_SRC
- get some keys value according to a list in a dictionary:
#+BEGIN_SRC python
value = {}
for key in finance_vocab:
    value[key] = dict_vocab.get(key)

#+END_SRC
- filter dictionary by value:
#+BEGIN_SRC python
filtered_dict = {k:v for k,v in dict.items() if v<0}
#+END_SRC
- set all values in a dict:
#+BEGIN_SRC python
visited = dict.fromkeys(self.graph, False)
#+END_SRC
- check if a value is in a dict:
#+BEGIN_SRC python
'红鲱鱼招股书' in g.graph.values()
#+END_SRC
- check if a value is in a defaultdict collection list:
#+BEGIN_SRC python
any('波动性' in v for v in g.graph.values())
# or
def in_values(s, d):
    """Does `s` appear in any of the values in `d`?"""
    for v in d.values():
        if s in v:
            return True
    return False

in_values('cow', animals)
#+END_SRC

- sort a dict by its value:
#+BEGIN_SRC python
s = [(k, d[k]) for k in sorted(d, key=d.get, reverse=True)]
#+END_SRC
- count key values in a dict:
#+BEGIN_SRC python
d = defaultdict(list)
for name in g.graph.keys():
	key = len(g.graph[name])
	d[name] = key
#+END_SRC
- convert a list of tuples with the same key into a dictionary:
#+BEGIN_SRC python
from collections import defaultdict
d = defaultdict(list)
for k, v in list(graph.out_edges('财务管理')):
    d[k].append(v)
# or
d = {}
for k, v in list(graph.out_edges('财务管理')):
    d.setdefault(k,[]).append(v)
#+END_SRC

- multiply diction by another dictionary:
#+BEGIN_SRC python
from copy import copy
my_dict = copy(another_dict)
my_dict.update((x, y*2) for x, y in my_dict.items())
#+END_SRC
- add value in a dictionary:
#+BEGIN_SRC python
In [231]: d
Out[231]:
defaultdict(list,
            {'上海证券交易所上市公司': 383,
             '各证券交易所上市公司': 37,
             '深圳证券交易所上市公司': 511,
             '证券': 64,
             '证券交易所': 8})

sum(d.values())
#+END_SRC

- write defaultdict to a json file:
#+BEGIN_SRC python
import json
# writing
json.dump(yourdict, open(filename, 'w'))
# reading
yourdict = json.load(open(filename))
#+END_SRC
** Context Manager Types
** Other Built-in Types
** Special Attributes -- magic method:
- getitem in a class allows its instances to use the [ ] (indexer) operators
- setitem Called to implement assignment to self[key]
- call magic method in a class causes its instances to become callables – in other words, those instances now behave like functions.
- getattr overrides Python’s default mechanism for member access.
- getattr magic method only gets invoked for attributes that are not in the dict magic attribute. Implementing getattr causes the hasattr built-in function to always return True, unless an exception is raised from within getattr.
- setattr allows you to override Python’s default mechanism for member assignment.
- The repr function also converts an object to a string. It can also be invoked using the reverse quotes (`), also called accent grave, (underneath the tilde, ~, on most keyboards). But it will convert unambitiously the object. For example, repr(datetime.datetime.now) = datetime.datetime(2018, 1, 20, 13, 32, 51, 483232).
- __str__
get string of elements inside.
#+begin_src python :tangle yes
print `a`
print repr(a)
#+end_src
- find out where module is installed
#+BEGIN_SRC python
import os
import spacy
print(os.path.dirname(spacy.__file__))
#+END_SRC

* Built-in Exceptions
** Base classes
** Concrete exceptions
** Warnings
** Exception hierarchy
** exception
- retry:
#+BEGIN_SRC python
response = None
error = None
while response is None:
  try:
    response = doing_something()
    if response is not None:
      if 'good' in response:
        print("successfully uploaded")
      else:
        exit("reason %s"%response)
  except HttpError as e:
    if e.code in RETRIABLE_STATUS_CODES:
      error = 'A retriable HTTP error %d occurred:\n%s' % (e.resp.status,
                                                             e.content)
    else:
      raise
  except RETRIABLE_EXCEPTIONS as e:
    error = 'A retriable error occurred: %s' % e

    if error is not None:
      print error
      retry += 1
      if retry > MAX_RETRIES:
        exit('No longer attempting to retry.')

      max_sleep = 2 ** retry
      sleep_seconds = random.random() * max_sleep
      print 'Sleeping %f seconds and then retrying...' % sleep_seconds
      time.sleep(sleep_seconds)
#+END_SRC
- capture urllib error:
#+BEGIN_SRC python
import urllib2

req = urllib2.Request('http://www.python.org/fish.html')
try:
    resp = urllib2.urlopen(req)
except urllib2.HTTPError as e:
    if e.code == 404:
        # do something...
    else:
        # ...
except urllib2.URLError as e:
    # Not an HTTP-specific error (e.g. connection refused)
    # ...
else:
    # 200
    body = resp.read()

#+END_SRC
- create an exception:
#+BEGIN_SRC python
class ConstraintError(Exception):
    def __init__(self, arg):
        self.args = arg


if error:
    raise ConstraintError("error")


class Networkerror(RuntimeError):
    def __init__(self, arg):
        self.args = arg


try:
    raise Networkerror("Bad hostname")
except Networkerror,e:
    print e.args
    print e.message
#+END_SRC
- clean-up actions
#+BEGIN_SRC python
>>> def divide(x, y):
...     try:
...         result = x / y
...     except ZeroDivisionError:
...         print "division by zero!"
...     else:
...         print "result is", result
...     finally:
...         print "executing finally clause"
...
>>> divide(2, 1)
result is 2
executing finally clause
>>> divide(2, 0)
division by zero!
executing finally clause
>>> divide("2", "1")
executing finally clause
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in divide
TypeError: unsupported operand type(s) for /: 'str' and 'str'

#+END_SRC
* Text Processing Services
** string — Common string operations
- check if string is Chinese:
#+BEGIN_SRC python
from googletrans import Translator
translator = Translator(proxies ={
             'http': 'http://192.168.1.126:1080',
             'https': 'http://192.168.1.126:1080'
         }
)
input_text_language_0 = translator.detect(input_text_0).lang
#+END_SRC

- find if strings are almost equal:
#+BEGIN_SRC python
from difflib import SequenceMatcher
s_1 = 'Mohan Mehta'
s_2 = 'Mohan Mehte'
print(SequenceMatcher(a=s_1,b=s_2).ratio())
0.909090909091
#+END_SRC
- check if string is empty:
#+BEGIN_SRC python
if not text:
  print('text is empty')
#+END_SRC
- if the string is an English word.
#+BEGIN_SRC python
from nltk.corpus import wordnet
if not wordnet.synsets(word) and not word.isdigit()
#+END_SRC
- jieba cut, remove signs.
#+BEGIN_SRC python
punct = set(u''':!),.:;?]}¢'"、。〉》」』】〕〗〞︰︱︳﹐､﹒
﹔﹕﹖﹗﹚﹜﹞！），．：；？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠
々‖•·ˇˉ―--′’”([{£¥'"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻
︽︿﹁﹃﹙﹛﹝（｛“‘-—_…''')

str_in = u"小明硕士毕业于中国科学院计算所，\
后在日本京都大学深造，凭借过人天赋，旁人若在另一方面爱他，他每即躲开。"

# 对str/unicode
filterpunt = lambda s: ''.join(filter(lambda x: x not in punct, s))
# 对list
filterpuntl = lambda l: list(filter(lambda x: x not in punct, l))
seg_list = jieba.cut(str_in, cut_all=False)
sent_list = filterpuntl(seg_list)
#+END_SRC
- jieba cut on bash:
#+BEGIN_SRC bash
python -m jieba news.txt > cut_result.txt
#+END_SRC
 - create a list from jieba generator:
   sentence = [x for x in seg_list]
- tokenize unicode or string to sentence list.
#+BEGIN_SRC python
from nltk import tokenize as n_tokenize
sent= n_tokenize.sent_tokenize(page)
# or
sent_list = page.split()
#+END_SRC
- list comprehension
#+BEGIN_SRC python
[x for x in t if x not in s if x.isdigit()]
l = [22, 13, 45, 50, 98, 69, 43, 44, 1]
[True if x >= 45 else False for x in l]
#+END_SRC
- if string are digits.
#+BEGIN_SRC python
str.isdigit()
#+END_SRC
- concatenate two strings
#+BEGIN_SRC python
" ".join((str1, str2))
#+END_SRC
- 移除字符串头尾指定的字符（默认为空格）
#+BEGIN_SRC python
#!/usr/bin/python

str = "0000000this is string example....wow!!!0000000";
print(str.strip( '0' ))
#+END_SRC

- checks whether the string consists of alphabetic characters only.
#+BEGIN_SRC python 2
#!/usr/bin/python

str = "this";  # No space & digit in this string
print(str.isalpha())

str = "this is string example....wow!!!";
print(str.isalpha())
#+END_SRC

#+RESULTS:
: True
: False

** re — Regular expression operations
*** useage:
- find strings
- convert strings
- convert syntax from python2 to python3
#+BEGIN_SRC txt
regular expression: find print(\S*), replace with print(\1)
#+END_SRC
*** types:
In : rex_property.search?
Signature: rex_property.search(string=None, pos=0, endpos=9223372036854775807, *, pattern=None)
Docstring:
Scan through string looking for a match, and return a corresponding match object instance.
This object has start, end, group, groups, span.

Return None if no position in the string matches.
Type:      builtin_function_or_method

In : rex_property.findall?
Signature: rex_property.findall(string=None, pos=0, endpos=9223372036854775807, *, source=None)
Docstring: *Return a list* of all non-overlapping matches of pattern in string.
Type:      builtin_function_or_method

In : rex_property.match?
Signature: rex_property.match(string=None, pos=0, endpos=9223372036854775807, *, pattern=None)
Docstring: Matches zero or more characters at the beginning of the string.
Type:      builtin_function_or_method

*** string array
[Pp]ython: find Python or python

**** parts
re.search('[a-zA-Z0-9]', 'x')

**** not
re.search('[^0-9]', 'x')

**** shortcut

- word: \w
- number: \d
- space, tab, next line: \s
- 0 length sub string: \b
re.search('\bcorn\b', 'corner')

**** start and end with strings
#+BEGIN_SRC python
re.search('^Python', 'Python 3')
re.search('Python$', 'this is Python')
#+END_SRC

**** any character
"."

**** all lines contain a specific string
#+BEGIN_SRC python
^.*Deeplearning4j$
#+END_SRC
*** optional words
'color' vs 'colour'
re.search('colou?r', 'my favoriate color')

*** repeat
{N}

#+BEGIN_SRC python
# find a telephone number
re.search(r'[\d]{3}-[\d]{4}', '867-5309 /Jenny')

# find 32big GID
[x for x in risk_model_merge.keys() if re.match("[A-Z0-9]{32}$", x)]
#+END_SRC

**** boundary of repeated times
[\d]{3,4}

**** open selection
[\d]{3,}

**** speed selection
- +: {1,}
- *: {0,}

*** search for a pattern within a text file
- bulk read:
#+BEGIN_SRC python
import re

textfile = open(filename, 'r')
filetext = textfile.read()
textfile.close()
matches = re.findall("(<(\d{4,5})>)?", filetext)

#+END_SRC

- read line by line:
#+BEGIN_SRC python
import re

textfile = open(filename, 'r')
matches = []
reg = re.compile("(<(\d{4,5})>)?")
for line in textfile:
    matches += reg.findall(line)
textfile.close()
#+END_SRC

** difflib — Helpers for computing deltas
** textwrap — Text wrapping and filling
** unicodedata — Unicode Database
https://docs.python.org/2.7/howto/unicode.html
** stringprep — Internet String Preparation
** readline — GNU readline interface

* Data Types
** datetime — Basic date and time types
- Converting unix timestamp string to readable date in Python
#+BEGIN_SRC python
import datetime
print(
    datetime.datetime.fromtimestamp(
        int("1284101485")
    ).strftime('%Y-%m-%d %H:%M:%S')
)

#+END_SRC
** Time
- create timestamp:
#+BEGIN_SRC python
>>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')
datetime.datetime(1300, 1, 1, 0, 0)
#+END_SRC
- get specific timezone datetime
#+begin_src python
tz = pytz.timezone('America/Los_Angeles')
#date = date.today()
now = datetime.now()
los_angeles_time = datetime.now(tz)
#+end_src

- use tqdm as a status bar:
#+begin_src python
from tqdm import tqdm
from time import sleep
for i in tqdm(range(10)):
    sleep(0.1)

# enumerate
for i in enumerate(tqdm(list)):
    do things()
# pandas 
df = pd.DataFrame(np.random.randint(0, int(1e8), (10000, 1000)))

# Create and register a new `tqdm` instance with `pandas`
# (can use tqdm_gui, optional kwargs, etc.)
tqdm.pandas()

# Now you can use `progress_apply` instead of `apply`
df.groupby(0).progress_apply(lambda x: x**2)

#+end_src

- string to datetime:
#+begin_src python
time.strptime(string[, format])
#+end_src

- datetime, Timestamp, datetime64
pandas, Timestamp
np.dtype('<M8[ns]')

-- DatetimeIndex is composed by Timestamps.
#+BEGIN_SRC python
#Timestamp to string:i
str_timestamp = pd.to_datetime(Timestamp, format = '%Y%m%d')
str_timestamp = str_timestamp.strftime('%Y-%m-%d')
#+END_SRC
datetime, utc
datetime64
- get the location of a date in datetimeindex:
#+BEGIN_SRC python
pd.DatetimeIndex.get_loc(datetime)
#+END_SRC
- datetime off set, subtract
#+BEGIN_SRC python
TimeStamp +/- pd.DateOffset(years=1)
pd.Timedelta(days=365) #allowed keywords are [weeks, days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds]
#+END_SRC
** calendar — General calendar-related functions
** collections — Container datatypes
** collections — High-performance container datatypes

| module      | function                                                             |
|-------------+----------------------------------------------------------------------|
| deque       | list-like container with fast appends and pops on either end         |
| Counter     | dict subclass for counting hashable objects                          |
| defaultdict | dict subclass that calls a factory function to supply missing values |

** collections.abc — Abstract Base Classes for Containers
** heapq — Heap queue algorithm
** bisect — Array bisection algorithm
** array — Efficient arrays of numeric values
** weakref — Weak references
** types — Dynamic type creation and names for built-in types
** copy — Shallow and deep copy operations
#+BEGIN_SRC python
from copy import copy
#+END_SRC
** pprint — Data pretty printer
适合打印列表。
#+BEGIN_SRC python
>>> import pprint
>>> tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',
... ('parrot', ('fresh fruit',))))))))
>>> stuff = ['a' * 10, tup, ['a' * 30, 'b' * 30], ['c' * 20, 'd' * 20]]
>>> pprint.pprint(stuff)
['aaaaaaaaaa',
 ('spam',
  ('eggs',
   ('lumberjack',
    ('knights', ('ni', ('dead', ('parrot', ('fresh fruit',)))))))),
 ['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'],
 ['cccccccccccccccccccc', 'dddddddddddddddddddd']]
#+END_SRC
** reprlib — Alternate repr() implementation
** enum — Support for enumerations
* Numeric and Mathematical Modules
** numbers — Numeric abstract base classes
** math — Mathematical functions
** cmath — Mathematical functions for complex numbers
** decimal — Decimal fixed point and floating point arithmetic
Floating-point numbers are represented in computer hardware as base 2 (binary) fractions. For example, the decimal fraction 0.001 has value 0/2 + 0/4 + 1/8.
On a typical machine running Python, there are 53 bits of precision available for a Python float, so the value stored internally when you enter the decimal number 0.1 is the binary fraction.
#+begin_src emacs-lisp :tangle yes
0.00011001100110011001100110011001100110011001100110011010
#+end_src
#+begin_src emacs-lisp :tangle yes
>>> round(2.675, 2)
2.67
#+end_src
it’s again replaced with a binary approximation, whose exact value is

2.67499999999999982236431605997495353221893310546875
- precision, scientific number:
#+BEGIN_SRC python
import numpy as np
np.set_printoptions(suppress=True)
%precision %.4g
#+END_SRC
** fractions — Rational numbers
** random — Generate pseudo-random numbers
** statistics — Mathematical statistics functions
* Functional Programming Modules
** itertools — Functions creating iterators for efficient looping
** functools — Higher-order functions and operations on callable objects
** operator — Standard operators as functions
* File and Directory Access
** pathlib — Object-oriented filesystem paths
** os.path — Common pathname manipulations
- move file
#+BEGIN_SRC python
import os
os.move(source_file_path, destination)
#+END_SRC
- find current working dir:
#+BEGIN_SRC python
import sys, os
# run python file.py
ROOTDIR = os.path.join(os.path.dirname(__file__), os.pardir)
sys.path.append(os.path.join(ROOTDIR, "lib"))
# run in python
ROOTDIR = os.path.join(os.path.dirname("__file__"), os.pardir)
#+END_SRC
- temperary folder:
#+BEGIN_SRC python
import os
import tempfile
TEMP_FOLDER = tempfile.gettempdir()
print('Folder "{}" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))
#+END_SRC
- walk all file from a directory and its sub-directory
Directory tree generator.

For each directory in the directory tree rooted at top (including top
itself, but excluding '.' and '..'), yields a 3-tuple

    dirpath, dirnames, filenames
#+BEGIN_SRC  python
import os
from os.path import join, getsize
for root, dirs, files in os.walk('/home/weiwu/share/deep_learning/data/enwiki'):
    print(root, "consumes, ")
    print(sum([getsize(join(root, name)) for name in files]), '\s')
    print("bytes in", len(files), "non-directory files")
#+END_SRC

- check if file exist
#+BEGIN_SRC python
os.path.isfile(os.path.join(path,name))
#+END_SRC
- get current work directory
#+BEGIN_SRC python
import os
cwd = os.getcwd()
#+END_SRC
- get temporary work directory
#+BEGIN_SRC python
from tempfile import gettempdir
tmp_dir = gettempdir()
#+END_SRC
** fileinput — Iterate over lines from multiple input streams
- open
open() returns a file object, and is most commonly used with two arguments: open(filename, mode).
#+BEGIN_SRC python
>>> f = open('workfile', 'w')
>>> print f
<open file 'workfile', mode 'w' at 80a0960>
#+END_SRC
The first argument is a string containing the filename. The second argument is another string containing a few characters describing the way in which the file will be used. mode can be 'r' when the file will only be read, 'w' for only writing (an existing file with the same name will be erased), and 'a' opens the file for appending; any data written to the file is automatically added to the end. 'r+' opens the file for both reading and writing. The mode argument is optional; *r* will be assumed if it’s omitted.

On Windows, 'b' appended to the mode opens the file in binary mode, so there are also modes like 'rb', 'wb', and 'r+b'.
- write text at the end of a file without overwrite that file:
#+BEGIN_SRC python
f = open('filename.txt', 'a')
f.write("stuff")
f.close()
#+END_SRC
- read specific lines
#+BEGIN_SRC python
fp = open("file")
for i, line in enumerate(fp):
    if i == 25:
        # 26th line
    elif i == 29:
        # 30th line
    elif i > 29:
        break
fp.close()
# Note that i == n-1 for the nth line.

# In Python 2.6 or later:
with open("file") as fp:
    for i, line in enumerate(fp):
        if i == 25:
            # 26th line
        elif i == 29:
            # 30th line
        elif i > 29:
            break
#+END_SRC
** stat — Interpreting stat() results
** filecmp — File and Directory Comparisons
** tempfile — Generate temporary files and directories
** glob — Unix style pathname pattern expansion
** fnmatch — Unix filename pattern matching
** linecache — Random access to text lines
** shutil — High-level file operations
** macpath — Mac OS 9 path manipulation functions
* Data Persistence
** pickle — Python object serialization
*** dump:
#+BEGIN_SRC python
import pickle

data1 = {'a': [1, 2.0, 3, 4+6j],
         'b': ('string', u'Unicode string'),
         'c': None}

selfref_list = [1, 2, 3]
selfref_list.append(selfref_list)

output = open('data.pkl', 'wb')

# Pickle dictionary using protocol 0.
pickle.dump(data1, output)

# Pickle the list using the highest protocol available.
pickle.dump(selfref_list, output, -1)

output.close()
pickle.dump( x0, open( "x0.pkl", "wb" ) )
#+END_SRC

*** load:
- read all the objects in the pickle dump file:
#+BEGIN_SRC python
pickle_file = open('./data/city_20190228.pkl', 'rb')
dict_disease_seed_graph = []
while True:
    try:
        dict_disease_seed_graph.append(pickle.load(pickle_file))
    except EOFError:
        pickle_file.close()
        break
#+END_SRC

#+BEGIN_SRC python
import pprint, pickle

pkl_file = open('data.pkl', 'rb')

data1 = pickle.load(pkl_file)
pprint.pprint(data1)

data2 = pickle.load(pkl_file)
pprint.pprint(data2)

pkl_file.close()
#+END_SRC
** copyreg — Register pickle support functions
** shelve — Python object persistence
** marshal — Internal Python object serialization
** dbm — Interfaces to Unix “databases”
** sqlite3 — DB-API interface for SQLite databases
- install mysql connector
python ModuleNotFoundError: No module named 'mysql'
#+BEGIN_SRC bash
pip search mysql-connector | grep --color mysql-connector-python
pip install mysql-connector-python-rf
#+END_SRC
** protobuf
*** tutorial
- need a .proto file for the structure:
#+BEGIN_SRC proto
syntax = "proto3"; // or proto2
package tutorial;

import "google/protobuf/timestamp.proto";
// [END declaration]

// [START java_declaration]
option java_package = "com.example.tutorial";
option java_outer_classname = "AddressBookProtos";
// [END java_declaration]

// [START csharp_declaration]
option csharp_namespace = "Google.Protobuf.Examples.AddressBook";
// [END csharp_declaration]

// [START messages]
message Person {
  string name = 1;
  int32 id = 2;  // Unique ID number for this person.
  string email = 3;

  enum PhoneType {
    MOBILE = 0;
    HOME = 1;
    WORK = 2;
  }

  message PhoneNumber {
    string number = 1;
    PhoneType type = 2;
  }

  repeated PhoneNumber phones = 4;

  google.protobuf.Timestamp last_updated = 5;
}

// Our address book file is just one of these.
message AddressBook {
  repeated Person people = 1;
}

#+END_SRC
- Compiling Your Protocol Buffers in shell to generate a class:
#+BEGIN_SRC bash
protoc -I=$SRC_DIR --python_out=$DST_DIR $SRC_DIR/addressbook.proto
protoc --proto_path=src --python_out=build/gen src/foo.proto src/bar/baz.proto
# The compiler will read the files src/foo.proto and src/bar/baz.proto and produce two output files: build/gen/foo_pb2.py and build/gen/bar/baz_pb2.py. The compiler will automatically create the directory build/gen/bar if necessary, but it will not create build or build/gen; they must already exist.
#+END_SRC
- add_person.py
#+BEGIN_SRC python
#! /usr/bin/python

import addressbook_pb2
import sys

# This function fills in a Person message based on user input.
def PromptForAddress(person):
  person.id = int(raw_input("Enter person ID number: "))
  person.name = raw_input("Enter name: ")

  email = raw_input("Enter email address (blank for none): ")
  if email != "":
    person.email = email

  while True:
    number = raw_input("Enter a phone number (or leave blank to finish): ")
    if number == "":
      break

    phone_number = person.phones.add()
    phone_number.number = number

    type = raw_input("Is this a mobile, home, or work phone? ")
    if type == "mobile":
      phone_number.type = addressbook_pb2.Person.MOBILE
    elif type == "home":
      phone_number.type = addressbook_pb2.Person.HOME
    elif type == "work":
      phone_number.type = addressbook_pb2.Person.WORK
    else:
      print "Unknown phone type; leaving as default value."

# Main procedure:  Reads the entire address book from a file,
#   adds one person based on user input, then writes it back out to the same
#   file.
if len(sys.argv) != 2:
  print "Usage:", sys.argv[0], "ADDRESS_BOOK_FILE"
  sys.exit(-1)

address_book = addressbook_pb2.AddressBook()

# Read the existing address book.
try:
  f = open(sys.argv[1], "rb")
  address_book.ParseFromString(f.read())
  f.close()
except IOError:
  print sys.argv[1] + ": Could not open file.  Creating a new one."

# Add an address.
PromptForAddress(address_book.people.add())

# Write the new address book back to disk.
f = open(sys.argv[1], "wb")
f.write(address_book.SerializeToString())
f.close()
#+END_SRC
- try to run above python code in shell:
#+BEGIN_SRC bash
python add_person.py ADDRESS_BOOK_FILE
#+END_SRC
- list_person.py
#+BEGIN_SRC python
#! /usr/bin/python

import addressbook_pb2
import sys

# Iterates though all people in the AddressBook and prints info about them.
def ListPeople(address_book):
  for person in address_book.people:
    print "Person ID:", person.id
    print "  Name:", person.name
    if person.HasField('email'):
      print "  E-mail address:", person.email

    for phone_number in person.phones:
      if phone_number.type == addressbook_pb2.Person.MOBILE:
        print "  Mobile phone #: ",
      elif phone_number.type == addressbook_pb2.Person.HOME:
        print "  Home phone #: ",
      elif phone_number.type == addressbook_pb2.Person.WORK:
        print "  Work phone #: ",
      print phone_number.number

# Main procedure:  Reads the entire address book from a file and prints all
#   the information inside.
if len(sys.argv) != 2:
  print "Usage:", sys.argv[0], "ADDRESS_BOOK_FILE"
  sys.exit(-1)

address_book = addressbook_pb2.AddressBook()

# Read the existing address book.
f = open(sys.argv[1], "rb")
address_book.ParseFromString(f.read())
f.close()

ListPeople(address_book)
#+END_SRC
- read a message:
#+BEGIN_SRC bash
python list_person.py ADDRESS_BOOK_FILE
#+END_SRC
** neo4j
*** install
#+BEGIN_SRC bash
pip install neo4j-driver py2neo

#+END_SRC
*** basic operations
- create cursor:
#+BEGIN_SRC python
g = Graph(host="192.168.4.36",  # neo4j 搭载服务器的ip地址，ifconfig可获取到
            http_port=7474,  # neo4j 服务器监听的端口号
            user="neo4j",  # 数据库user name，如果没有更改过，应该是neo4j
            password="neo4j123")
#+END_SRC
* Data Compression and Archiving
** zip
zip([iterable, ...])
This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. The returned list is truncated in length to the length of the shortest argument sequence. When there are multiple arguments which are all of the same length, zip() is similar to map() with an initial argument of None. With a single sequence argument, it returns a list of 1-tuples. With no arguments, it returns an empty list.

The left-to-right evaluation order of the iterables is guaranteed. This makes possible an idiom for clustering a data series into n-length groups using zip(*[iter(s)]*n).

zip() in conjunction with the * operator can be used to unzip a list:
#+BEGIN_SRC shell
>>>
>>> x = [1, 2, 3]
>>> y = [4, 5, 6]
>>> zipped = zip(x, y)
>>> zipped
[(1, 4), (2, 5), (3, 6)]
>>> x2, y2 = zip(*zipped)
>>> x == list(x2) and y == list(y2)
True
#+END_SRC
- create a dictionary with two iterables
#+BEGIN_SRC python
>>> x = [1, 2, 3]
>>> y = [4, 5, 6]
>>> zipped = zip(x, y)
>>> zipped
[(1, 4), (2, 5), (3, 6)]
In [172]: dict(zipped)
Out[179]: {1: 4, 2: 5, 3: 6}

#+END_SRC
** zlib — Compression compatible with gzip
** gzip — Support for gzip files
** bz2 — Support for bzip2 compression
** lzma — Compression using the LZMA algorithm
** zipfile — Work with ZIP archives
** tarfile — Read and write tar archive files
* File Formats
** csv — CSV File Reading and Writing
** *args, **kwargs
如果我们不确定要往函数中传入多少个参数，或者我们想往函数中以列表和元组的形式传参数时，那就使要用*args；
#+BEGIN_SRC python
>>> args = ("two", 3,5)
>>> test_args_kwargs(*args)
arg1: two
arg2: 3
arg3: 5

#+END_SRC
如果我们不知道要往函数中传入多少个关键词参数，或者想传入字典的值作为关键词参数时，那就要使用**kwargs。args和kwargs这两个标识符是约定俗成的用法，你当然还可以用*bob和**billy，但是这样就并不太妥。
#+BEGIN_SRC python
>>> kwargs = {"arg3": 3, "arg2": "two","arg1":5}
>>> test_args_kwargs(**kwargs)
arg1: 5
arg2: two
arg3: 3

#+END_SRC
** configparser — Configuration file parser
- use yaml and config file.
#+BEGIN_SRC yaml
# config.yaml
engine:
  user:
    'jack'
  password:
    'password'
#+END_SRC

#+BEGIN_SRC python
import yaml
with open(r'config.yaml', 'rb') as f:
    config = yaml.load(f)

#+END_SRC
- ylib.yaml_config
#+BEGIN_SRC python
from ylib.yaml_config import Configuraion
config = Configuraion()
config.load('../config.yaml')
print(config.__str__)

USER_AGENT = config.USER_AGENT
DOMAIN = config.DOMAIN
BLACK_DOMAIN = config.BLACK_DOMAIN
URL_SEARCH = config.URL_SEARCH

#+END_SRC
** netrc — netrc file processing
** xdrlib — Encode and decode XDR data
** plistlib — Generate and parse Mac OS X .plist files
* Cryptographic Services
** hashlib — Secure hashes and message digests
** hmac — Keyed-Hashing for Message Authentication
** secrets — Generate secure random numbers for managing secrets
* Generic Operating System Services
** os — Miscellaneous operating system interfaces
** io — Core tools for working with streams
** time — Time access and conversions
** argparse — Parser for command-line options, arguments and sub-commands
*** 16.4.2. ArgumentParser objects
class argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True)
Create a new ArgumentParser object. All parameters should be passed as keyword arguments. Each parameter has its own more detailed description below, but in short they are:

prog - The name of the program (default: sys.argv[ 0])
usage - The string describing the program usage (default: generated from arguments added to parser)
description - Text to display before the argument help (default: none)
epilog - Text to display after the argument help (default: none)
parents - A list of ArgumentParser objects whose arguments should also be included
formatter_class - A class for customizing the help output
prefix_chars - The set of characters that prefix optional arguments (default: ‘-‘)
fromfile_prefix_chars - The set of characters that prefix files from which additional arguments should be read (default: None)
argument_default - The global default value for arguments (default: None)
conflict_handler - The strategy for resolving conflicting optionals (usually unnecessary)
add_help - Add a -h/--help option to the parser (default: True)
allow_abbrev - Allows long options to be abbreviated if the abbreviation is unambiguous. (default: True)
*** argument_default
#+BEGIN_SRC python
>>> parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS)
>>> parser.add_argument('--foo')
>>> parser.add_argument('bar', nargs='?')
>>> parser.parse_args(['--foo', '1', 'BAR'])
Namespace(bar='BAR', foo='1')
>>> parser.parse_args([])
Namespace()
#+END_SRC
*** example
#+BEGIN_SRC python
import argparse

logger = logging.getLogger()
handler = logging.StreamHandler()
formatter = logging.Formatter(
    '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')
handler.setFormatter(formatter)
if not logger.handlers:
    logger.addHandler(handler)
    logger.setLevel(logging.DEBUG)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-i", "--input", required=False, help="Input word2vec model")
    parser.add_argument(
        "-o", "--output", required=False, help="Output tensor file name prefix")
    parser.add_argument(
        "-b",
        "--binary",
        required=False,
        help="If word2vec model in binary format, set True, else False")
    parser.add_argument(
        "-l",
        "--logdir",
        required=False,
        help="periodically save model variables in a checkpoint")
    parser.add_argument(
        "--host",
        required=False,
        help="host where holding the tensorboard projector service")
    parser.add_argument("-p", "--port", required=False, help="browser port")
    args = parser.parse_args()

    word2vec2tensor(args.input, args.output, args.binary)

#+END_SRC
*** another way to define function parameters and provide parameters:
- define function parameters inside a function:
#+BEGIN_SRC python
def convert_pdf2txt(args=None):
    import argparse
    P = argparse.ArgumentParser(description=__doc__)
    P.add_argument(
        "-m", "--maxpages", type=int, default=0, help="Maximum pages to parse")

    A = P.parse_args(args=args)
    print(A.maxpages)
#+END_SRC
- provide parameters:
#+BEGIN_SRC python
# all parameters should be strings
convert_pdf2txt(['--maxpages', '123'])
#+END_SRC
** getopt — C-style parser for command line options
** logging — Logging facility for Python
#+BEGIN_SRC python

import logging
logger = logging.getLogger()
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')
handler.setFormatter(formatter)
if not logger.handler:
    logger.addHandler(handler)
logger.setLevel(logging.DEBUG)
logger
# or
logging.basicConfig(
    format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)

# at the end of the program
handler.close()
logger.removeHandler(handler)
#+END_SRC

- ylog
#+BEGIN_SRC python
from ylib import ylog
import logging

ylog.set_level(logging.DEBUG)
ylog.console_on()
ylog.filelog_on("app")

#+END_SRC
** logging.config — Logging configuration
** logging.handlers — Logging handlers
** getpass — Portable password input
** curses — Terminal handling for character-cell displays
** curses.textpad — Text input widget for curses programs
** curses.ascii — Utilities for ASCII characters
** curses.panel — A panel stack extension for curses
** platform — Access to underlying platform’s identifying data
** errno — Standard errno system symbols
** ctypes — A foreign function library for Python
* Concurrent Execution
** threading — Thread-based parallelism
** threading & queue
*** install
#+BEGIN_SRC shell
pip install queuelib
#+END_SRC
*** example
#+BEGIN_SRC python
from Queue import Queue
import threading

#+END_SRC
** multiprocessing — Process-based parallelism
** The concurrent package
** concurrent.futures — Launching parallel tasks
** subprocess — Subprocess management
** sched — Event scheduler
** queue — A synchronized queue class
** dummy_threading — Drop-in replacement for the threading module
** _thread — Low-level threading API
** _dummy_thread — Drop-in replacement for the _thread module

* Internet Data Handling
** Jupyter notebook
*** Using a virtualenv in an IPython notebook
1. Install the ipython kernel module into your virtualenv
#+BEGIN_SRC python
workon my-virtualenv-name  # activate your virtualenv, if you haven't already
pip install ipykernel
#+END_SRC

2. Now run the kernel "self-install" script:
#+BEGIN_SRC python
python -m ipykernel install --user --name=my-virtualenv-name
#+END_SRC

3. list all the kernels
#+BEGIN_SRC python
jupyter kernelspec list
#+END_SRC

4. remove uninstall kernel
#+BEGIN_SRC python
jupyter kernelspec uninstall anaconda2.7
#+END_SRC
** typical structure of the ipython notebook ipynb:
1. imports
2. get data
3. transform data
4. modeling
5. visualization
6. making sense of the data

summary:
- notebook should have one hypothesis data interpretation loop
- make a multi-project utils library
- each cell should have one and only one output
- try to keep code inside notebooks.

** fetch data from yahoo
install pandas-datareader first.
#+BEGIN_SRC shell
conda install pandas-datareader
#+END_SRC

#+begin_src python
import pandas as pd
import datetime as dt
import numpy as np
from pandas_datareader import data as web

data = pd.DataFrame()
symbols = ['GLD', 'GDX']
for sym in symbols:
    data[sym] = web.DataReader(sym, data_source='yahoo', start='20100510')['Adj Close']
data = data.dropna()
#+end_src

** email — An email and MIME handling package
** json — JSON encoder and decoder
** Graph
*** networkx
- add node to a graph
- add edges to a graph
- find a loop/cycle in a graph
#+BEGIN_SRC python
nx.find_cycle(G)
list(nx.simple_cycles(G))
#+END_SRC


* Internet Protocols and Support
** webbrowser — Convenient Web-browser controller
** cgi — Common Gateway Interface support
** cgitb — Traceback manager for CGI scripts
** wsgiref — WSGI Utilities and Reference Implementation
** urllib — URL handling modules
** urllib.request — Extensible library for opening URLs
** urllib.response — Response classes used by urllib
** urllib.parse — Parse URLs into components
** urllib.error — Exception classes raised by urllib.request
** urllib.robotparser — Parser for robots.txt
** http — HTTP modules
** http.client — HTTP protocol client
** ftplib — FTP protocol client
** poplib — POP3 protocol client
** imaplib — IMAP4 protocol client
** nntplib — NNTP protocol client
** smtplib — SMTP protocol client
** smtpd — SMTP Server
** telnetlib — Telnet client
** uuid — UUID objects according to RFC 4122
** socketserver — A framework for network servers
** http.server — HTTP servers
** http.cookies — HTTP state management
** http.cookiejar — Cookie handling for HTTP clients
** xmlrpc — XMLRPC server and client modules
** xmlrpc.client — XML-RPC client access
** xmlrpc.server — Basic XML-RPC servers
** ipaddress — IPv4/IPv6 manipulation library

* Development Tools
** typing — Support for type hints
** pydoc — Documentation generator and online help system
** doctest — Test interactive Python examples
** unittest — Unit testing framework
- check data operation:
  - create, select, update, delete.

- purpose of unit test
  - checking parameter types, classes, or values.
  - checking data structure invariants.
  - checking “can’t happen” situations (duplicates in a list, contradictory state variables.)
  - after calling a function, to make sure that its return is reasonable.

** unittest.mock — mock object library
** unittest.mock — getting started

** test — Regression tests package for Python
** test.support — Utilities for the Python test suite
* Debugging and Profiling
** bdb — Debugger framework
** faulthandler — Dump the Python traceback
** pdb — The Python Debugger
- s(tep):

Execute the current line, stop at the first possible occasion (either in a function that is called or in the current function).

- n(ext):

Continue execution until the next line in the current function is reached or it returns.

- unt(il):

Continue execution until the line with a number greater than the current one is reached or until the current frame returns.

- r(eturn):
- c(ont(inue)):

Continue execution, only stop when a breakpoint is encountered.

- l(ist): [first [,last]]

List source code for the current file. Without arguments, list 11 lines around the current line or continue the previous listing. With one argument, list 11 lines starting at that line. With two arguments, list the given range; if the second argument is less than the first, it is a count.

- a(rgs):

Print the argument list of the current function.

- p expression:

Print the value of the expression.
** The Python Profilers
STEPS:
1). install snakeviz using pip from cmd.
#+BEGIN_SRC shell
pip install snakeviz
#+END_SRC

2). profile the test python file using below command.
#+BEGIN_SRC shell
$ python -m cProfile -o profile.stats test.py
#+END_SRC
#+BEGIN_SRC python
# test.py
from random import randint
max_size = 10**4
data = [randint(0, max_size) for _ in range(max_size)]
test = lambda: insertion_sort(data)

#+END_SRC

3). check the efficiency result from profile.stats file.
#+BEGIN_SRC shell
$ snakeviz profile.stats
#+END_SRC

** timeit — Measure execution time of small code snippets
** trace — Trace or track Python statement execution
** tracemalloc — Trace memory allocations
* Software Packaging and Distribution
** pip
- install with a wheel .whl file:
#+BEGIN_SRC bash
pip install *.whl
#+END_SRC
- Upgrading pip
#+BEGIN_SRC bash
pip install -U pip
#+END_SRC
- add below setup to ~/.pip/pip.conf
#+begin_src txt
[global]
#index-url=https://pypi.mirrors.ustc.edu.cn/simple/
#index-url=https://pypi.python.org/simple/
index-url=http://mirrors.aliyun.com/pypi/simple/
#index-url=https://pypi.gocept.com/pypi/simple/
#index-url=https://mirror.picosecond.org/pypi/simple/
[install]
trusted-host=mirrors.aliyun.com
#trusted-host=mirrors.ustc.edu.cn
#+end_src
- generate a requirements file:
#+BEGIN_SRC bash
pip freeze > requirements.txt
#+END_SRC
- pip install directly:
requirements.txt
#+begin_src txt
--index-url http://mirrors.aliyun.com/pypi/simple/
pandas
pylint
pep8
sphinx
ipython
numpy
ipdb
mock
nose
#+end_src
** distutils — Building and installing Python modules
** ensurepip — Bootstrapping the pip installer
** venv — Creation of virtual environments
** zipapp — Manage executable python zip archives
** pyenv — Simple Python version management
- check installed versions
#+BEGIN_SRC shell
pyenv versions
#+END_SRC

#+RESULT:
:  system
:  2.7.13
:  3.6.0
:  3.6.0/envs/general
:  3.6.0/envs/simulate
:  3.6.0/envs/venv3.6.0
:  3.6.0/envs/venv3.6.0.1
: * anaconda3-4.4.0 (set by /home/weiwu/projects/simulate/.python-version)
:  general
:  simulate
:  venv3.6.0
:  venv3.6.0.1

* Python Runtime Services
** sysconfig — Provide access to Python’s configuration information
** os, sys — System-specific parameters and functions
- get environment variables
#+BEGIN_SRC python
import os

env_dist = os.environ # environ是在os.py中定义的一个dict environ = {}

print(env_dist.get('JAVA_HOME'))
print(env_dist['JAVA_HOME'])

#+END_SRC
- check if file or directory exists, if not then make directory:
#+BEGIN_SRC python
import os
os.path.exists(test_file.txt)
os.path.isfile("test-data")
export_dir = "export/"
if not os.path.exists(export_dir):
    os.mkdir(export_dir)
#+END_SRC

 - read a file:
import os
folder = '/file/path'
file = os.path.join(folder, 'file_name')

- list all the files under a directory:
#+BEGIN_SRC python
# os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 '.' 和'..' 即使它在文件夹中.
path = os.getcwd()
dirs = os.listdir(path)
#+END_SRC

- check if the file readable:
#+BEGIN_SRC python
import os
if os.access("/file/path/foo.txt", os.F_OK):
    print "Given file path is exist."

if os.access("/file/path/foo.txt", os.R_OK):
    print "File is accessible to read"

if os.access("/file/path/foo.txt", os.W_OK):
    print "File is accessible to write"

if os.access("/file/path/foo.txt", os.X_OK):
    print "File is accessible to execute"

#+END_SRC
- use sys to get command arguments:
#+BEGIN_SRC python
#!/usr/bin/python3

import sys

print ('参数个数为:', len(sys.argv), '个参数。')
print ('参数列表:', str(sys.argv))

#+END_SRC
#+BEGIN_SRC shell
$ python3 test.py arg1 arg2 arg3
参数个数为: 4 个参数。
参数列表: ['test.py', 'arg1', 'arg2', 'arg3']
#+END_SRC

** builtins — Built-in objects
** __main__ — Top-level script environment
** warnings — Warning control
- SettingWithCopyWarning in Pandas
#+BEGIN_SRC python
pd.options.mode.chained_assignment = None  # default='warn'
#+END_SRC
- RuntimeWarning in numpy:
numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
#+BEGIN_SRC python
import warnings
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")

#+END_SRC

** contextlib — Utilities for with-statement contexts
** abc — Abstract Base Classes
** atexit — Exit handlers
** traceback — Print or retrieve a stack traceback
** __future__ — Future statement definitions
从Python 2.7到Python 3.x就有不兼容的一些改动，比如2.x里的字符串用'xxx'表示str，Unicode字符串用u'xxx'表示unicode，而在3.x中，所有字符串都被视为unicode，因此，写u'xxx'和'xxx'是完全一致的，而在2.x中以'xxx'表示的str就必须写成b'xxx'，以此表示“二进制字符串”。

要直接把代码升级到3.x是比较冒进的，因为有大量的改动需要测试。相反，可以在2.7版本中先在一部分代码中测试一些3.x的特性，如果没有问题，再移植到3.x不迟。

Python提供了__future__模块，把下一个新版本的特性导入到当前版本，于是我们就可以在当前版本中测试一些新版本的特性。
#+BEGIN_SRC python
from __future__ import print_function
from __future__ import division
from __future__ import unicode_literals
from __future__ import absolute_import
#+END_SRC
- unicode vs utf-8 vs binary strings vs strings
unicode 是编码unique code,例如把一个汉字编成了一个码(计算机不可读).

A chinese character:      汉

it's unicode value:       U+6C49

convert 6C49 to binary:   01101100 01001001

UTF-8是把character转为binary code的规范, and vice versa. 方便存储。
|   binary |          |          |          |                     |                                   |
| 1st Byte | 2nd Byte | 3rd Byte | 4th Byte | Number of Free Bits | Maximum Expressible Unicode Value |
| 0xxxxxxx |          |          |          | 7                   | 007F hex (127)                    |
| 110xxxxx | 10xxxxxx |          |          | (5+6)=11            | 07FF hex (2047)                   |
| 1110xxxx | 10xxxxxx | 10xxxxxx |          | (4+6+6)=16          | FFFF hex (65535)                  |
| 11110xxx | 10xxxxxx | 10xxxxxx | 10xxxxxx | (3+6+6+6)=21        | 10FFFF hex (1,114,111)            |

已知“严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此“严”的UTF-8编码需要三个字节，即格式是“1110xxxx 10xxxxxx 10xxxxxx”。然后，从“严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，“严”的UTF-8编码是“11100100 10111000 10100101”，转换成十六进制就是E4B8A5。

You can use a different encoding from UTF-8 by putting a specially-formatted comment as the first or second line of the source code:

# -*- coding: <encoding name> -*-

*是为了让解释器在执行该文件的时候知道该文件是何种编码方式，从而顺利读取指令去执行计算。*
- division
新的除法特性，本来的除号`/`对于分子分母是整数的情况会取整，但新特性中在此情况下的除法不会取整，取整的使用`//`。如下可见，只有分子分母都是整数时结果不同。
- print_function
新的print是一个函数，如果导入此特性，之前的print语句就不能用了。
- unicode_literals
这个是对字符串使用unicode字符

** gc — Garbage Collector interface
** inspect — Inspect live objects
- find the folder of a module:
#+BEGIN_SRC python
import inspect
inspect.getfile(Module)
#+END_SRC
** site — Site-specific configuration hook
** fpectl — Floating point exception control
* Custom Python Interpreters
** code — Interpreter base classes
** codeop — Compile Python code
* Importing Modules
** Module
- reload a module/lib in ipython without killing it.
#+BEGIN_SRC python
# For Python 2 use built-in function reload():

reload(module)
# For Python 2 and 3.2–3.3 use reload from module imp:

import imp
imp.reload(module)
# or
import importlib
importlib.reload(module)
#+END_SRC
- 当你运行一个Python模块 python fibo.py <arguments>
  Remember, everything in python is an object.

- python解释器CPython.

- 如果字符串里面有’\’,而实际上要把斜杠加到字符串里面，要在前面加r，代表raw. 例如r’Y:\codes’.

- 如果主目录下有子目录packages，记得要在子目录下加init.py，最好在主目录下建main.py函数。

- 解释器如果执行哪个一个文件为主程序，如 python program1.py，it will set the special variable name to program1.py equals to ‘main’
- One of the reasons for doing this is that sometimes you write a module (a .py file) where it can be executed directly. Alternatively, it can also be imported and used in another module. By doing the main check, you can have that code only execute when you want to run the module as a program and not have it execute when someone just wants to import your module and call your functions themselves.

- 模块中的代码将会被执行，就像导入它一样，不过此时name 被设置为 “main“。这意味着，通过在你的模块末尾添加此代码.

- can’t import module from upper directory.

    - need to add the working directory to .bashrc PYTHONPATH
    - using ipython.
- Add custom folder path to the Windows environment.
  add PYTHONEXE%; to System Variable PATH;
  add System variable name: PYTHONEXE , value: C:\Users\Wei Wu\Anaconda2;C:\Users\Wei Wu\Python\ylib\src\py\;
  add PYTHONPATH:  C:\Users\Wei Wu\Anaconda2;C:\Users\Wei Wu\Python\ylib\src\py\;
  or add module path in Spyder directly;
- import module temperarily from parental directory without add path to the system.
#+begin_src python :tangle yes
# folder1
#    \__init__.py
#    \State.py
#    \StateMachine.py
#    \mouse_folder
#        \MouseAction.py
import os,sys,inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0,parentdir+'\\mouse')
sys.path.insert(0,parentdir)

from State import State
from StateMachine import StateMachine
from MouseAction import MouseAction
#+end_src

- check module path:
#+begin_src python
import os
print os.path.abspath(ylib.__file__)
#+end_src

- make a python 3 virtual environment:
#+begin_src sh
mkvirtual -p python3 ENVNAME
#+end_src

- install setup.py:
python setup.py install
to virtual environment:
/home/weiwu/.virtualenvs/data_analysis/bin/python2 setup.py install

- install from github:
pip install git+https://github.com/quantopian/zipline.git
#+BEGIN_SRC bash
conda uninstall tqdm
easy_install git+https://github.com/quantopian/zipline.git
#+END_SRC
- change conda source:
#+BEGIN_SRC shell
conda config --add channels 'https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/'
conda config --set show_channel_urls yes
#+END_SRC

- easy_install multiple versions, remove version:
#+BEGIN_SRC python
import pkg_resources
pkg_resources.require("gensim")  # latest installed version
pkg_resources.require("gensim==3.7.2")  # this exact version
pkg_resources.require("gensim>=3.7.2")  # this version or higher

#+END_SRC
- create conda virtualenv:
#+BEGIN_SRC shell
# 创建 conda 虚拟环境（ :code:`env_name` 是您希望创建的虚拟环境名）
$ conda create --name env_name python=3.5

# 如您想创建一个名为rqalpha的虚拟环境
$ conda create --name rqalpha python=3.5

# 使用 conda 虚拟环境
$ source activate env_name
# 如果是 Windows 环境下 直接执行 activcate
$ activate env_name

# 退出 conda 虚拟环境
$ source deactivate env_name
# 如果是 Windows 环境下 直接执行 deactivate
$ deactivate env_name

# 删除 conda 虚拟环境
$ conda-env remove --name env_name

# add conda for all users
sudo ln -s /share/anaconda3/etc/profile.d/conda.sh /etc/profile.d/conda.sh
# Previous to conda 4.4, the recommended way to activate conda was to modify PATH in
# your ~/.bashrc file.  You should manually remove the line that looks like

    export PATH="/share/anaconda3/bin:$PATH"

# ^^^ The above line should NO LONGER be in your ~/.bashrc file! ^^^

#+END_SRC

- percentage output format:
#+begin_src python
from future import division
print “%s %.4f%%” % (sid, (len(not_close)/len(ctp)))
#+end_src
** zipimport — Import modules from Zip archives
** pkgutil — Package extension utility
** modulefinder — Find modules used by a script
** runpy — Locating and executing Python modules
** importlib — The implementation of import
* Python Language Services
** parser — Access Python parse trees
** ast — Abstract Syntax Trees
** symtable — Access to the compiler’s symbol tables
** symbol — Constants used with Python parse trees
** token — Constants used with Python parse trees
** keyword — Testing for Python keywords
** tokenize — Tokenizer for Python source
** tabnanny — Detection of ambiguous indentation
** pyclbr — Python class browser support
** py_compile — Compile Python source files
** compileall — Byte-compile Python libraries
** dis — Disassembler for Python bytecode
** pickletools — Tools for pickle developers
* Miscellaneous Services
** formatter — Generic output formatting
* MS Windows Specific Services
** msilib — Read and write Microsoft Installer files
** msvcrt — Useful routines from the MS VC++ runtime
** winreg — Windows registry access
** winsound — Sound-playing interface for Windows
* Unix Specific Services
** posix — The most common POSIX system calls
** pwd — The password database
** spwd — The shadow password database
** grp — The group database
** crypt — Function to check Unix passwords
** termios — POSIX style tty control
** tty — Terminal control functions
** pty — Pseudo-terminal utilities
** fcntl — The fcntl and ioctl system calls
** pipes — Interface to shell pipelines
** resource — Resource usage information
** nis — Interface to Sun’s NIS (Yellow Pages)
** syslog — Unix syslog library routines
* Superseded Modules
** optparse — Parser for command line options
** imp — Access the import internals
* Undocumented Modules
** Platform specific modules
** call java service
#+BEGIN_SRC python
import subprocess
try:
    subprocess.call(["java",
                     "-jar", grobid_jar,
                     # Avoid OutOfMemoryException
                     "-Xmx1024m",
                     "-gH", grobid_home,
                     "-gP", os.path.join(grobid_home,
                                         "config/grobid.properties"),
                     "-dIn", pdf_folder,
                     "-exe", "processReferences"])
    return True
except subprocess.CalledProcessError:
    return False

#+END_SRC
* Data Analysis:
** pandas:
[[file:./pandas.org][advanced pandas]]
- add new columns to a dataframe:
#+BEGIN_SRC python
>>> df = pd.DataFrame([[i] for i in range(10)], columns=['num'])
>>> df
    num
0    0
1    1
2    2
3    3

>>> def powers(x):
>>>     return x, x**2, x**3, x**4, x**5, x**6

>>> df['p1'], df['p2'], df['p3'], df['p4'], df['p5'], df['p6'] = \
>>>     zip(*df['num'].map(powers))

#+END_SRC
- first day of the previous month:
#+BEGIN_SRC python
today = datetime.datetime.today()
the_last_day_of_previous_month = today  datetime.timedelta(days=1)
the_first_day_of_previous_month = the_last_day_of_previous_month.replace(day=1)
#+END_SRC
- N month before:
#+BEGIN_SRC python
today - pd.Timedelta(1, unit=’M’)
#+END_SRC
- pandas columns into default dictionary:
#+BEGIN_SRC python
df_patient[['pid','med_clinic_id']].groupby('pid').apply(lambda x:x['med_clinic_id'].tolist()).to_dict()
#+END_SRC
- filter by groupby count size:
#+BEGIN_SRC python
df_patient = df_patient.groupby(['hos_id', 'disease']).filter(lambda x:x['person_id'].unique().size>=3)
#+END_SRC 
- apply to each group in groupby:
#+BEGIN_SRC python
for group in df2.groupby('type'):
    print(group_id, group[0])
    data = group[1]
    if group[0] == 'A':
        print group[1].min()
#+END_SRC
- apply to a column for each row:
#+BEGIN_SRC python
df = pd.DataFrame([[1,2,3],[4,5,6]], columns=['a','b','c'])
def rowFunc(row):
    return row['a'] + row['b'] * row['c']

def rowIndex(row):
    return row.name
df['d'] = df.apply(rowFunc, axis=1)
df['rowIndex'] = df.apply(rowIndex, axis=1)
df
Out[182]:
   a  b  c   d  rowIndex
0  1  2  3   7         0
1  4  5  6  34         1
#+END_SRC
- permutation of an array:
#+BEGIN_SRC python
person_id = df_disease_sample['person_id'].unique()
from itertools import permutations
perm = permutations(person_id, 2)
df_person_similarity_adj_matrix = pd.DataFrame(index=perm, columns=['similarity'])
df_person_similarity_adj_matrix
#+END_SRC
- remove value in pandas index:
#+BEGIN_SRC python
index.drop('value')
#+END_SRC
- select rows with value in multiple columns:
#+BEGIN_SRC python
df_suspicious_pairs[df_suspicious_pairs[['person_id_1', 'person_id_2']].isin(['11076976']).any(axis=1)]
def add_edges(G, row, df_suspicious_pairs):
    person_id = row.index
    df_targets = df_suspicious_pairs[df_suspicious_pairs[['person_id_1', 'person_id_2']].isin(person_id).any(axis=1)]
    G.add_edges_from([tuple(x) for x in df_targets[['person_id_1', 'person_id_2']].values])


df_suspicious_person.progress_apply(lambda x: add_edges(G, x, df_suspicious_pairs))
#+END_SRC
- delete rows that contain string value in a column:
#+BEGIN_SRC python
df_disease_sample[~df_disease_sample['treatment_code'].str.contains('DE')]
#+END_SRC
- pandas values to dict:
#+BEGIN_SRC python
med_hos_id_mapping.set_index('med_clinic_id')['hos_id'].to_dict()
#+END_SRC
- create dataframe from a list of tuples:
#+BEGIN_SRC python
pd.DataFrame.from_records([tuples])
#+END_SRC
- create multiple index for index:
#+BEGIN_SRC python
similarity_rank.index = pd.MultiIndex.from_tuples(similarity_rank.index)
#+END_SRC
- groupby, transform, agg:
#+BEGIN_SRC python
df = pd.DataFrame(dict(A=list('aabb'), B=[1, 2, 3, 4], C=[0, 9, 0, 9]))
# groupby is the standard use aggregater
df.groupby('A').mean()
# maybe you want these values broadcast across the whole group and return something with the same index as what you started with.
# use transform

df.groupby('A').transform('mean')
# is equalvilent to groupby("A").mean()
df.set_index('A').groupby(level='A').transform('mean')

# agg is used when you have specific things you want to run for different columns or more than one thing run on the same column.

df.groupby('A').agg(['mean', 'std'])


#+END_SRC

- read oracle database UnicodeDecodeError:
#+BEGIN_SRC python
import cx_Oracle as cx
import pandas as pd
import numpy as np
import os
from tqdm import *
import os
from sqlalchemy import create_engine


os.environ['NLS_LANG'] = 'SIMPLIFIED CHINESE_CHINA.UTF8'

engine = create_engine('oracle://MMAPV41:MMAPV411556@192.168.4.32:1521/orcl?charset=utf8')

conn=cx.connect('MMAPV41/MMAPV411556@192.168.4.32/orcl')
sql_regist = """
select med_clinic_id, person_id, person_nm, person_sex, 
person_age, in_hosp_date, out_hosp_date, 
med_ser_org_no, clinic_type, in_diag_dis_nm, out_diag_doc_cd, 
med_amout, hosp_lev from t_kc21
"""
df_regist = pd.read_sql_query(sql_regist, engine)

s_med_clinic_id = pd.read_pickle('med_clinic_id.pkl')
n = 100
sql_regist = """
select med_clinic_id, person_id, person_nm, person_sex, 
person_age, in_hosp_date, out_hosp_date, 
med_ser_org_no, clinic_type, in_diag_dis_nm, out_diag_doc_cd, 
med_amout, hosp_lev from t_kc21 where med_clinic_id in (%s)
"""
df_regist = pd.DataFrame()
for i in tqdm(range(0, int(len(s_med_clinic_id)/100), n)):
    s = "'"+','.join(s_med_clinic_id.ix[i:(i+n)].values.flatten()).replace(',',"','")+"'"
    sql = sql_regist%(s)
    try:
        df_regist_iter = pd.read_sql(sql, conn)
        df_regist = df_regist.append(df_regist_iter)
    except UnicodeDecodeError:
        continue
df_regist.to_pickle("registration_data.pkl")

#+END_SRC
- find rows with nearest dates/value:
#+BEGIN_SRC python
df_result = pd.DataFrame()
for idx, value in enumerate(groups):
    df_target_group = df_patient.loc[value]
    df_target_group.sort_values('入院日期', inplace=True)
    df_target_group['checkin_diff'] = df_target_group['入院日期'].diff()/np.timedelta64(1, 'D')
    df_target_group.reset_index(inplace=True)
    index = df_target_group[df_target_group['checkin_diff']<=3].index
    result = pd.concat([df_target_group.loc[index], df_target_group.loc[index-1]]).sort_values('入院日期')
    result.drop_duplicates(['个人ID','入院日期'], inplace=True)
    result['group'] = idx
    result['hospitals'] = result['机构'].unique().shape[0]
    df_result = df_result.append(result.drop('checkin_diff',axis=1))
#+END_SRC
- save to excel sheet:
#+BEGIN_SRC python
writer = pd.ExcelWriter('nanjing_result.xlsx')
df_nanjing.to_excel(writer,'全部分组')
big_groups.to_excel(writer,'超大组')
writer.save()
#+END_SRC
- concate multiple columns into one column:
#+BEGIN_SRC python
diff_checkout_next_checkin['date'] = dataframe.loc[index, columns].stack().sort_values()
diff_checkout_next_checkin['diff'] = diff_checkout_next_checkin['date'].diff()/np.timedelta64(1, 'M')

#+END_SRC
- sort values:
#+BEGIN_SRC python
df_nanjing.sort_values(['group_sn', '个人ID', '入院日期'], inplace=True)
#+END_SRC
- read excel:
#+BEGIN_SRC python
df_nanjing = pd.read_excel('result.xlsx',dtype={'证件号':str,
                                                '个人ID':str},
                         parse_dates=['入院日期','出院日期'])
#+END_SRC
- groupby group size:
#+BEGIN_SRC python
group_size = df_nanjing.groupby(['group_sn'])['个人ID'].unique().apply(len)
big_groups = df_nanjing[df_nanjing['group_sn'].isin(group_size[group_size >= 8].index)]
small_groups = df_nanjing[df_nanjing['group_sn'].isin(group_size[group_size < 8].index)]
#+END_SRC
- create a dataframe from a dictionary:
#+BEGIN_SRC python
df = pd.DataFrame.from_dict({}, orient='index')
#+END_SRC
- get unique columns value groups:
#+BEGIN_SRC python
rels = ['疾病名称','诊疗大类2']
rels_cure = df_cure.groupby(rels).size().reset_index()[rels].values.tolist()
#+END_SRC
- fill na with previous column:
#+BEGIN_SRC python
df_tree.fillna(method='pad', axis=1, inplace=True)
#+END_SRC
- delete a column in a dataframe:
#+BEGIN_SRC python
del df['column']
#+END_SRC
- create node edges
#+BEGIN_SRC python
def create_node(label, nodes):
    count = 0
    for node_name in tqdm(nodes):
        node = Node(label, name=node_name)
        # g.schema.create_uniqueness_constraint(label, node_name)
        try:
            g.create(node)
            count += 1
        except ClientError:
            continue
        # debug(count)
    return


'''创建实体关联边'''
def create_relationship(start_node, end_node, edges, rel_type, rel_name):
    count = 0
    # 去重处理
    set_edges = []
    for edge in edges:
        try:
            set_edges.append('###'.join(edge))
        except TypeError:
            continue
    all = len(set(set_edges))
    for edge in tqdm(set(set_edges)):
        edge = edge.split('###')
        p = edge[0]
        q = edge[1]
        if p==q:
            continue
        query = "match(p:%s),(q:%s) where p.name='%s'and q.name='%s' create (p)-[rel:%s{name:'%s'}]->(q)" % (
            start_node, end_node, p, q, rel_type, rel_name)
        try:
            g.run(query)
            count += 1
            # debug(rel_type)
        except Exception as e:
            info(e)
    return

'''创建知识图谱中心疾病的节点'''
def create_diseases_nodes(disease_infos):
    count = 0
    for disease_dict in tqdm(disease_infos):
        node = Node("Disease", name=disease_dict['name'], desc=disease_dict['desc'],
                    prevent=disease_dict['prevent'] ,cause=disease_dict['cause'],
                    easy_get=disease_dict['easy_get'],cure_lasttime=disease_dict['cure_lasttime'],
                    cure_department=disease_dict['cure_department']
                    ,cure_way=disease_dict['cure_way'] , cured_prob=disease_dict['cured_prob'])
        g.create(node)
        # count += 1
        # debug(count)
    return
#+END_SRC
- select rows by column values:
#+BEGIN_SRC python
df[(df['a'].isin(condition1)&(df['a'].isin(condition2))]
df[df['a']==a]
df_insurance_disease = df_insurance[(df_insurance['type']=='医疗费用-疾病') & (df_insurance['year'].isin(years[4:]))]

#+END_SRC
- create tuples or dictionary from two columns:
#+BEGIN_SRC python
dict(df[['a', 'b']].values.tolist())
[tuple(x) for x in df[['a', 'b', 'c']].values]
#+END_SRC
- mapping:
#+BEGIN_SRC python
dictionary = df_mapping.set_index('a')['b'].to_dict()
df['a'].map(dict)
#+END_SRC
- filter not null, filter not NaT rows:
since strings data types have variable length, it is by default stored as object dtype. If you want to store them as string type, you can do something like this.
#+BEGIN_SRC python
df_text.ix[df_text.Conclusion.values.nonzero()[0]]
df['column'] = df['column'].astype('|S80') #where the max length is set at 80 bytes,
# or alternatively

df['column'] = df['column'].astype('|S') # which will by default set the length to the max len it encounters
#+END_SRC
- change datatypes
#+BEGIN_SRC python
df.a.astype(float)
drinks['beer_servings'] = drinks.beer_servings.astype(float)
#+END_SRC
- change date type to string:
#+BEGIN_SRC python
drinks['beer_servings'] = drinks.beer_servings.astype('str)

#+END_SRC
- read csv without header, delimiter is space:
#+BEGIN_SRC python
vocab = pd.read_csv("/home/weiwu/share/deep_learning/data/model/phrase/zhwiki/categories/三板.vocab",delim_whitespace=True,header=None)
#+END_SRC
- parse text in csv
#+BEGIN_SRC python
reddit_news = pd.read_csv('/home/weiwu/share/deep_learning/data/RedditNews.csv')
DJA_news = pd.read_csv(
    '/home/weiwu/share/deep_learning/data/Combined_News_DJIA.csv')
na_str_DJA_news = DJA_news.iloc[:, 2:].values
na_str_DJA_news = na_str_DJA_news.flatten()
na_str_reddit_news = reddit_news.News.values
sentences_reddit = [s.encode('utf-8').split() for s in na_str_reddit_news]
sentences_DJA = [s.encode('utf-8').split() for s in na_str_DJA_news]
#+END_SRC
- rank
DataFrame.rank(axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)[source]
Compute numerical data ranks (1 through n) along axis. Equal values are assigned a rank that is the average of the ranks of those values

- n largest value
DataFrame.nlargest(n, columns, keep='first')
Get the rows of a DataFrame sorted by the n largest values of columns.

#+BEGIN_SRC python
>>> df = DataFrame({'a': [1, 10, 8, 11, -1],
...                 'b': list('abdce'),
...                 'c': [1.0, 2.0, np.nan, 3.0, 4.0]})
>>> df.nlargest(3, 'a')
    a  b   c
3  11  c   3
1  10  b   2
2   8  d NaN

#+END_SRC
- quantile
DataFrame.quantile(q=0.5, axis=0, numeric_only=True, interpolation='linear')[source]
Return values at the given quantile over requested axis, a la numpy.percentile.
#+BEGIN_SRC python
>>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),
                   columns=['a', 'b'])
>>> df.quantile(.1)
a    1.3
b    3.7
dtype: float64
>>> df.quantile([.1, .5])
       a     b
0.1  1.3   3.7
0.5  2.5  55.0
#+END_SRC

- generate a dataframe:
#+begin_src python
dates = pd.date_range('1/1/2000', periods=8)
df = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])
# or
df = pd.DataFrame(data={'a':[1,2],'b':[3,3]})
#+end_src

- create diagonal matrix/dataframe using a series:
#+BEGIN_SRC python
df = pd.DataFrame(np.diag(s), columns=Q.index)
#+END_SRC

- connection with mysql:
#+begin_src python
pandas.read_sql_query(sql, con=engine):
pandas.read_sql_table(table_name, con=engine):
pandas.read_sql(sql, con=engine)
sql = 'DROP TABLE IF EXISTS etf_daily_price;'
result = engine.execute(sql)
#+end_src
- dropna:
#+BEGIN_SRC python
DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)

#+END_SRC
- melt.
pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)[source]

This function is useful to massage a DataFrame into a format where one or more columns are identifier variables (id_vars), while all other columns, considered measured variables (value_vars), are “unpivoted” to the row axis, leaving just two non-identifier columns, ‘variable’ and ‘value’.
#+BEGIN_SRC python
"""
Parameters:
frame : DataFrame
id_vars : tuple, list, or ndarray, optional
Column(s) to use as identifier variables.
value_vars : tuple, list, or ndarray, optional
Column(s) to unpivot. If not specified, uses all columns that are not set as id_vars.
var_name : scalar
Name to use for the ‘variable’ column. If None it uses frame.columns.name or ‘variable’.
value_name : scalar, default ‘value’
Name to use for the ‘value’ column.
col_level : int or string, optional
If columns are a MultiIndex then use this level to melt.
"""
DataFrame['idname'] = DataFrame.index
pd.melt(DataFrame, id_vars=['idname'])
#+END_SRC
#+RESULT:
: >>> import pandas as pd
: >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
: ...                    'B': {0: 1, 1: 3, 2: 5},
: ...                    'C': {0: 2, 1: 4, 2: 6}})
: >>> df
:    A  B  C
: 0  a  1  2
: 1  b  3  4
: 2  c  5  6
: >>> pd.melt(df, id_vars=['A'], value_vars=['B'])
:    A variable  value
: 0  a        B      1
: 1  b        B      3
: 2  c        B      5

- fill nan:
#+BEGIN_SRC python
DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
# method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None
#+END_SRC

- select non zero rows from series:
#+BEGIN_SRC python
s[s.nonzero()]
#+END_SRC

- create value by cretics
#+BEGIN_SRC python
df[df.col1.map(lambda x: x != 0)] = 1
#+END_SRC

- dataframe to series:
#+BEGIN_SRC python
s = df[df.columns[0]]
#+END_SRC

- replace value:
#+BEGIN_SRC python
DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)
df = df[df.line_race != 0]
#+END_SRC
- pandas has value:
#+BEGIN_SRC python
value in df['column_name']
set(a).issubset(df['a'])
#+END_SRC

- calculate percentage of sum on a row:
#+BEGIN_SRC python
df.apply(lambda x: x / x.sum() * 100, axis=0)
#+END_SRC

- pandas has null value:
#+BEGIN_SRC python
df.isnull().values.any()

#+END_SRC
- find all the values of TRUE in a dataframe:
#+begin_src python
z=(a!=b)
pd.concat([a.ix[z[reduce(lambda x, y: x | z[y], z, False)].index],b.ix[z[reduce(lambda x, y: x | z[y], z, False)].index]],axis=1)
#+end_src
- reduce
#+BEGIN_SRC python
from functools import reduce
reduce(lambda x, y: x+y, range(1,101))
#+END_SRC

- if array a is a subset of another array b:
#+BEGIN_SRC python
set(B).issubset(set(A))
#+END_SRC
- remove negative value from a column:
#+begin_src python
filtered_1=b[‘TRADE_size’].apply(lambda x: 0 if x < 0 else x)
b[‘TRADE_size’].loc[ b[‘TRADE_size’]<0, ‘TRADE_size’] = 0
#+end_src

- drop a lable:
#+BEGIN_SRC python
DataFrame.drop(labels, axis=0, level=None, inplace=False, errors='raise')
#+END_SRC

- check if any value is NaN in DataFrame
#+BEGIN_SRC python
df.isnull().values.any()
df.isnull().any().any()
#+END_SRC

- maximum & minimum value of a dataframe:
#+BEGIN_SRC python
df.values.max()
df.values.min()
#+END_SRC

- select value by creteria:
#+BEGIN_SRC python
logger.debug("all weight are bigger than 0? %s", (df_opts_weight>0).all().all())
logger.debug("all weight are smaller than 1? %s", (df_opts_weight<=1).all().all())
logger.debug("weight sum smaller than 0: %s", df_opts_weight[df_opts_weight<0].sum(1))
#+END_SRC

- count all duplicates:
#+BEGIN_SRC python
import pandas as pd
In [15]: a=pd.DataFrame({'a':['KBE.US','KBE.US','KBE.US','KBE.US','KBE.US','KBE.US','O.US','O.US','O.US','O.US','O.US'],'b':['KBE','KBE','KBE','KBE','KBE','KBE','O','O','O','O','O']})

In [16]: count = a.groupby('a').count()

In [20]: (count>5).all().all()
Out[20]: False

In [21]: (count>4).all().all()
Out[21]: True

- datetime64[ns] missing data, null:
For datetime64[ns] types, NaT represents missing values. This is a pseudo-native sentinel value that can be represented by numpy in a singular dtype (datetime64[ns]). pandas objects provide intercompatibility between NaT and NaN.

#+BEGIN_SRC python
In [16]: df2
Out[16]:
        one       two     three four   five  timestamp
a -0.166778  0.501113 -0.355322  bar  False 2012-01-01
c -0.337890  0.580967  0.983801  bar  False 2012-01-01
e  0.057802  0.761948 -0.712964  bar   True 2012-01-01
f -0.443160 -0.974602  1.047704  bar  False 2012-01-01
h -0.717852 -1.053898 -0.019369  bar  False 2012-01-01

In [17]: df2.loc[['a','c','h'],['one','timestamp']] = np.nan

In [18]: df2
Out[18]:
        one       two     three four   five  timestamp
a       NaN  0.501113 -0.355322  bar  False        NaT
c       NaN  0.580967  0.983801  bar  False        NaT
e  0.057802  0.761948 -0.712964  bar   True 2012-01-01
f -0.443160 -0.974602  1.047704  bar  False 2012-01-01
h       NaN -1.053898 -0.019369  bar  False        NaT
#+END_SRC
- rename column names:
#+begin_src python
df_bbg = df_bbg.rename(columns = lambda x: x[:4].replace(' ',''))
#+end_src
  - rename according to column value type:
    #+BEGIN_SRC python
    name = {2:'idname', 23:'value', 4:'variable'}
    df.rename(columns=lambda x: name[(gftIO.get_column_type(df,x))], inplace=True)
    #+END_SRC
  - rename column according to value:
  #+BEGIN_SRC python
name = {'INNERCODE': 'contract_code', 'OPTIONCODE': 'contract_name',
        'SETTLEMENTDATE': 'settlement_date', 'ENDDATE': 'date',
        'CLOSEPRICE': 'close_price'}
data.rename(columns=lambda x: name[x], inplace=True)

  #+END_SRC
- remove characters after space:
#+begin_src python
df_bbg = df_bbg.rename(columns = lambda x: x.)
#+end_src
- apply by group:
#+BEGIN_SRC python
df_long_term = small_groups.groupby('个人ID').progress_apply(lambda x: long_term_hospitalization(x[['入院日期', '出院日期']], days=30))
#+END_SRC
- pandas long format to pivot:
#+begin_src python
pivoted = df.pivot('name1','name2','name3')
specific_risk = self.risk_model['specificRisk'].pivot(
    index='date', columns='symbol', values='specificrisk')
df_pivot_industries_asset_weights = pd.pivot_table(
        df_industries_asset_weight, values='value', index=['date'],
        columns=['industry', 'symbol'])
#+end_src

- change the time or date or a datetime:
#+begin_src python
end = end.replace(hour=23, minute=59, second=59)
#+end_src

- 万德 wind python pandas
#+begin_src python
df = pd.Dataframe(data = w.wsd().Data[0], index=w.wsd().Times)
#+end_src

- check DatetimeIndex difference:
#+BEGIN_SRC python
# to check the frequency of the strategy, DAILY or MONTHLY
dt_diff = df_single_period_return.index.to_series().diff().mean()
if dt_diff < pd.Timedelta('3 days'):
#+END_SRC
- time delta
#+BEGIN_SRC python
import datetime
s + datetime.timedelta(minutes=5)
#+END_SRC
- resample by a column:
need to set the index as a datetime index, then use the resample function.

- resample by month and keep the last valid row
#+BEGIN_SRC python
benchmark_weight.index.name = 'Date'
m = benchmark_weight.index.to_period('m')
benchmark_weight = benchmark_weight.reset_index().groupby(m).last().set_index('Date')
benchmark_weight.index.name = ''
#+END_SRC

- groupby and sort by another column:
#+BEGIN_SRC python
df_input_text_entity.sort_values(['score'],ascending=False).groupby('mention').head(1) # only take the largest value of score
#+END_SRC

- filter two dataframe by columns' value
#+BEGIN_SRC python
pd.merge(df_input_text_entity_0, df_input_text_entity_1, on=['mention', 'entity'])
#+END_SRC

*** multiplying
- the multiplying calculation is not about the sequence of the index or column.

pandas will calculate on a sorted index and column value.
#+BEGIN_SRC python
In [87]: a=pd.DataFrame({'dog':[1,2],'fox':[3,4]},index=['a','b'])

In [88]: a
Out[88]:
   dog  fox
a    1    3
b    2    4

In [89]: b=pd.DataFrame({'fox':[1,2],'dog':[3,4]},index=['b','a'])

In [94]: b
Out[94]:
   dog  fox
b    3    1
a    4    2

In [95]: a*b
Out[95]:
   dog  fox
a    4    6
b    6    4
#+END_SRC

- dot multiplying
dot multiplying will sort the value.
#+BEGIN_SRC python
In [99]: a.dot(b.T)
Out[99]:
    b   a
a   6  10
b  10  16

In [100]: b.T
Out[104]:
     b  a
dog  3  4
fox  1  2

In [105]: a
Out[105]:
   dog  fox
a    1    3
b    2    4
#+END_SRC
*** Index

**** Index manuplication
- set column as datetime index
#+begin_src python
index = index.set_index(pd.DatetimeIndex(index['tradeDate'])).drop('tradeDate', axis=1)
# df = df.set_index(pd.DatetimeIndex(df['Date']))
#+end_src

- concaterate:
#+begin_src python
pd.concat([df1, df2], axis=0).sort_index()
pd.concat([df1, df2], axis=1)
result = df1.join(df2, how='outer’)
#+end_src

- check if the index is datetimeindex:
#+BEGIN_SRC python
if isinstance(df_otv.index, pd.DatetimeIndex):
    df_otv.reset_index(inplace=True)

#+END_SRC
- pandas are two dataframe identical
#+BEGIN_SRC python
pandas.DataFrame.equals()

#+END_SRC
- change index name:
#+begin_src python
df.index.names = ['Date']
#+end_src

- for loop in pandas dataframe:
#+begin_src python
for index, value in DataFrame:
#+end_src

- compare two time series:
#+begin_src python
s1[s1.isin(s2)]
ax = df1.plot()
df2.plot(ax=ax)
#+end_src

- datetime to string:
#+begin_src python
df.index.strftime("%Y-%m-%d %H:%M:%S")
#+end_src

- concaterate index
#+begin_src python
pd.concat([df1, df2], axis=1)
#+end_src
concate will take two dataframe to a new dataframe by index, preserving the columns.
A:
index variable value
B:
index variable value

pd.concat([A, B])
index variable value variable value
**** merge
merge will take two dataframe to a new dataframe by index, on the columns.
A:
index variable value
B:
index variable value

pd.merge(A, B, how='left', on=['index', 'variable'])
index variable value value
**** update
update dataframe1 with dataframe2

**** access hierarchical index.
  - A MultiIndex can be created from a list of arrays (using MultiIndex.from_arrays), an array of tuples (using MultiIndex.from_tuples), or a crossed set of iterables (using MultiIndex.from_product).
#+begin_src python
df.loc[‘date’,’col’], df[‘date’], df.ix[[‘date1’, ‘date2’]]
#+end_src

- slicing:
#+begin_src python
df.loc['start':'end',], df['start': 'end']
#+end_src

- slice with a ‘range’ of values, by providing a slice of tuples:
#+begin_src python
df.loc[('2006-11-02','USO.US'):('2006-11-06','USO.US')]
df.loc(axis=0)[:,['SPY.US']]
#+end_src

- select certain columns:
#+begin_src python
df.loc(axis=0)[:,['SPY.US']]['updatedTime']
#+end_src

- select rows with certain column value:
#+BEGIN_SRC python
df.loc[df['column_name'].isin(some_values)]
#+END_SRC

- select date range using pd series.
#+begin_src python
date_not_inserted = whole_index[~whole_index.isin(date_in_database['date'])]
df_need_to_be_updated = whole_df_stack.ix[days_not_in_db]
#+end_src

**** remove pandas duplicated index
***** #1
#+begin_src python
grouped = sym.groupby(level=0)
sym = grouped.last()
#+end_src

***** #2
#+begin_src python
df2[~df2.index.duplicated()]
#+end_SRC

***** remove duplicated rows
#+BEGIN_SRC python
pandas.DataFrame.drop_duplicates(subset=None, keep='first', inplace=False)
# subset : column label or sequence of labels, optional
#+END_SRC
**** convert a dataframe to an array:
#+begin_src emacs-lisp :tangle yes
pd.dataframe.to_matrix()
#+end_src

**** panel:
- create from dictionary:
#+BEGIN_SRC python
datetime_index = pd.DatetimeIndex(assets_group['date'].unique())
panel_model = pd.Panel({date: pd.DataFrame(0, index=assets.loc[date,'variable'],
                                           columns=assets.loc[date,'variable']) for date in datetime_index})
#+END_SRC
pandas panel item axis should be datetime64, this should not be an array.
**** unpivot multindex, multindex into colum:
#+BEGIN_SRC python
df_med_similarity_adj_matrix['similarity'] = df_med_similarity_adj_matrix.apply(
    lambda x: 1 - jaccard(docs[x.name[0]], docs[x.name[1]]), axis=1)

df_med_similarity_adj_matrix.index = pd.MultiIndex.from_tuples(df_med_similarity_adj_matrix.index)
df_med_similarity_adj_matrix.reset_index().pivot(index='level_0', columns='level_1', values='similarity')
#+END_SRC
** numpy
- numpy unique without sort:
#+BEGIN_SRC python
>>> import numpy as np
>>> a = [4,2,1,3,1,2,3,4]
>>> np.unique(a)
array([1, 2, 3, 4])
>>> indexes = np.unique(a, return_index=True)[1]
>>> [a[index] for index in sorted(indexes)]
[4, 2, 1, 3]

#+END_SRC
- plot histogram:
#+BEGIN_SRC python
>>> import matplotlib.pyplot as plt
>>> rng = np.random.RandomState(10)  # deterministic random data
>>> a = np.hstack((rng.normal(size=1000),
...                rng.normal(loc=5, scale=2, size=1000)))
>>> plt.hist(a, bins='auto')  # arguments are passed to np.histogram
>>> plt.title("Histogram with 'auto' bins")
>>> plt.show()
#+END_SRC
- quantile:
#+BEGIN_SRC python
numpy.quantile(a, q, axis=None, out=None, overwrite_input=False, interpolation='linear', keepdims=False)
#+END_SRC
- upper triangle matrix:
#+BEGIN_SRC python
import numpy as np

a = np.array([[1,2,3],[4,5,6],[7,8,9]])

#array([[1, 2, 3],
#       [4, 5, 6],
#       [7, 8, 9]])

a[np.triu_indices(3, k = 1)]

# this returns the following
array([2, 3, 6])
#+END_SRC
- sort an array by descending:
#+BEGIN_SRC python
In [25]: temp = np.random.randint(1,10, 10)

In [26]: temp
Out[26]: array([5, 2, 7, 4, 4, 2, 8, 6, 4, 4])

In [27]: id(temp)
Out[27]: 139962713524944

In [28]: temp[::-1].sort()

In [29]: temp
Out[29]: array([8, 7, 6, 5, 4, 4, 4, 4, 2, 2])

In [30]: id(temp)
Out[30]: 139962713524944
#+END_SRC
- save an array:
#+BEGIN_SRC python
import numpy as np
np.save(filename, array)
#+END_SRC
- maximum value in each row
#+BEGIN_SRC python
np.amax(ar, axis=1)
#+END_SRC
- from 2-D array to 1-D array with one column
#+BEGIN_SRC python
import numpy as np
a = np.array([[1],[2],[3]]))
a.flattern()
#+END_SRC
- Take a sequence of 1-D arrays and stack them as columns to make a single 2-D:
#+BEGIN_SRC python
numpy.column_stack(tup)
Parameters:
tup : sequence of 1-D or 2-D arrays.
Arrays to stack. All of them must have the same first dimension.
>>> a = np.array((1,2,3))
>>> b = np.array((2,3,4))
>>> np.column_stack((a,b))

- expand 1-D numpy array to 2-D:

#+END_SRC

- expand the shape of an array:
#+BEGIN_SRC python
numpy.expand_dims(a, axis)
# Expand the shape of an array.
# Insert a new axis that will appear at the axis position in the expanded array shape.
>>> x = np.array([1,2])
>>> x.shape
(2,)
>>> y = np.expand_dims(x, axis=0)
>>> y
array([[1, 2]])
>>> y.shape
(1, 2)
#+END_SRC

- count nan:
#+begin_src python
np.count_nonzero(~np.isnan(df['series']))
#+end_src

- count number of negative value:
#+begin_src python
np.sum((df < 0).values.ravel())
#+end_src

- check the difference of two arrays:
numpy.setdiff1d:
Return the sorted, unique values in ar1 that are not in ar2
#+BEGIN_SRC python
np.setdiff1d(ar1, ar2)
#+END_SRC
- sorted a list of tuples
#+BEGIN_SRC python
sorted(enumerate(sims), key=lambda item: -item[1])
#+END_SRC
- reshape:
np.reshape((1, -1)), -1 means automatic number of columns.

- select random symbols from a listdir:
#+BEGIN_SRC python
# get random symbols at the target position limit
position_limit = 8
arr = list(range(len(target_symbols)))
np.random.shuffle(arr)
target_symbols = target_symbols[arr[:position_limit]]
#+END_SRC
** plot:
*** subplot with the same axis:
pandas plot.
using matplotlib:
- plot different series on the same chart.
#+BEGIN_SRC python
cl_active_contract_pricing.plot()
cl_pricing.plot(style='k--')
#+END_SRC
- plot in ipython or jupyter notebook:
#+BEGIN_SRC python
ax = contract_data.plot(legend=True)
continuous_price.plot(legend=True, style='k--', ax=ax)
plt.show()
#+END_SRC
*** multiple figure一次绘制多个图形
- same plot, 多个figure:
#+BEGIN_SRC python
# figure.py

import matplotlib.pyplot as plt
import numpy as np

data = np.arange(100, 201)
plt.plot(data)

data2 = np.arange(200, 301)
plt.figure()
plt.plot(data2)

plt.show()
#+END_SRC

- multiple subplots 在同一个窗口显示多个图形
#+begin_src python
import matplotlib.pyplot as plt
fig = plt.figure()
ax1 = fig.add_subplot(2, 2, 1)
ax2 = fig.add_subplot(2, 2, 2)
ax3 = fig.add_subplot(2, 2, 3)
fig, axes = plt.subplots(2,3)
fig, ax : tuple
# or
data = np.arange(100, 201)
plt.subplot(2, 1, 1)
plt.plot(data)

data2 = np.arange(200, 301)
plt.subplot(2, 1, 2)
plt.plot(data2)

plt.show()
#+end_src
*** subplot with different axis
#+BEGIN_SRC python
plt.subplot(2, 1, 1)
plt.boxplot(x1)
plt.plot(1, x1.ix[-1], 'r*', markersize=15.0)

plt.subplot(2, 1, 2)
x1.plot()
# or
fig, axes = plt.subplots(2, 1, figsize=(10, 14))
axes[0].boxplot(pe000001)
axes[0].plot(1, pe000001.ix[-1], 'r*', markersize=15.0)

pe000001.plot()
#+END_SRC

*** plot a secondary y scale
#+begin_src python
df.price.plot(legend=True)
(100-df.pct_long).plot(secondary_y=True, style='g', legend=True)
#+end_src
- highlight a certain value in the plot:
#+begin_src python
a['DGAZ.US'].hist(bins=50)
plt.axvline(a['DGAZ.US'][-1], color='b', linestyle='dashed', linewidth=2)
#+end_src

*** plot seaborn:
- plot heatmap:
#+BEGIN_SRC python
figure = plt.figure(figsize=(12,12))
ax = sns.heatmap(temp, vmin=0, vmax=10, fmt="d", cmap="YlGnBu", annot=True)
# save plot
ax.get_figure()
figure.savefig('./images/test.png')
#+END_SRC
- save seaborn heatmap:
#+BEGIN_SRC python
plt.subplots(figsize=(12,12))

# fig, ax = plt.subplots(figsize=(12,12))
ax = sns.heatmap(temp, vmin=0, vmax=10, fmt="d", cmap="YlGnBu", annot=True)
# !!! can't save figure directly, need to get figure first.
figure = ax.get_figure()
figure.savefig('./images/%s.png'%(str(person_ids)))

#+END_SRC
*** plot a 3d figure:
#+begin_src python :tangle yes
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

strike = np.linspace(50, 150, 5)
ttm = np.linspace(0.5, 2.5, 8)

strike, ttm = np.meshgrid(strike, ttm)
iv = (strike - 100) ** 2 / (100 * strike) / ttm
fig = plt.figure(figsize=(9,6))
ax = fig.gca(projection='3d')
surf = ax.plot_surface(strike, ttm, iv, rstride=2, cstride=2,
                       cmap=plt.cm.coolwarm, linewidth=0.5,
                       antialiased=True)
fig.colorbar(surf, shrink=0.5, aspect=5)
#+end_src
fig is the :class:matplotlib.figure.Figure object.

- ax can be either a single axis object or an array of axis
- objects if more than one subplot was created.

[http://docs.pythontab.com/interpy/args_kwargs/Usage_args/]

[http://python.usyiyi.cn/python_278/library/index.html]

[https://docs.python.org/2/reference/simple_stmts.html?highlight=assert]

*** display Chinese:
#+BEGIN_SRC bash
➜  log git:(master) ✗ fc-list :lang=zh
/usr/share/fonts/truetype/wqy/wqy-microhei.ttc: 文泉驿微米黑,文泉驛微米黑,WenQuanYi Micro Hei:style=Regular
/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf: Droid Sans Fallback:style=Regular
/usr/share/fonts/truetype/wqy/wqy-microhei.ttc: 文泉驿等宽微米黑,文泉驛等寬微米黑,WenQuanYi Micro Hei Mono:style=Regular
#+END_SRC
#+BEGIN_SRC python
import matplotlib.font_manager as mfm
import matplotlib.pyplot as plt
font_path = "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"
prop = mfm.FontProperties(fname=font_path)
plt.text(0.5, 0.5, s=u'测试', fontproperties=prop)
plt.show()

#+END_SRC

*** stacked barplot, portfolio change
#+BEGIN_SRC python
pivot_df_insurance_accident = df_insurance_accident.pivot(
    index='year', columns='cat_age_sex', values='basic_insurance_fee')
pivot_df_insurance_disease.plot.bar(title='医疗保险-疾病纯保费',stacked=True, figsize=(10,7))

#+END_SRC
** scipy
-  combination k from n.
$$
{\displaystyle {\binom {n}{k}}={\frac {n(n-1)\dotsb (n-k+1)}{k(k-1)\dotsb 1}},} {\binom {n}{k}}={\frac {n(n-1)\dotsb (n-k+1)}{k(k-1)\dotsb 1}}$$

which can be written using factorials as$$ {\displaystyle \textstyle {\frac {n!}{k!(n-k)!}}} \textstyle {\frac {n!}{k!(n-k)!}} $$
#+BEGIN_SRC python
>>> from scipy.special import comb
>>> k = np.array([3, 4])
>>> n = np.array([10, 10])
>>> comb(n, k, exact=False)
array([ 120.,  210.])
>>> comb(10, 3, exact=True)
120L
>>> comb(10, 3, exact=True, repetition=True)
220L
#+END_SRC
[https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.comb.html]
** networkx:
- list edges of a node:
#+BEGIN_SRC python
G.neibors('node')
#+END_SRC
- count edges of a node:
#+BEGIN_SRC python
G.in_edges_degree()
G.out_edges_degree()
#+END_SRC
- create an edge:
#+BEGIN_SRC python
G.add_edges_from([(a,b)])
G.add_weighted_edges_from([(a,b,weight)])
#+END_SRC
- create a graph:
#+BEGIN_SRC python
G = nx.Graph()
# directed graph
G = nx.DiGraph()
#+END_SRC
- dump a graph:
#+BEGIN_SRC python
nx.write_gexf(G, 'file/path.gexf')
#+END_SRC
- draw a graph:
#+BEGIN_SRC python
nx.draw(G, with_labels=True)
#+END_SRC
* Machine learning:
** data processing:
- coding, mapping a list into range:
#+BEGIN_SRC python
from sklearn.preprocessing import LabelEncoder
class_label = LabelEncoder()
data["label"] = class_label.fit_transform(data["label"].values)
# or 
label_mapping = {label:idx for idx,label in enumerate(np.unique(data["label"]))}

#+END_SRC
- one hot coding:
#+BEGIN_SRC python
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
X = data[["color", "price"]].values
#通过类标编码将颜色装换成为整数
color_label = LabelEncoder()
X[:,0] = color_label.fit_transform(X[:,0])
#设置颜色列使用oneHot编码
one_hot = OneHotEncoder(categorical_features=[0])
print(one_hot.fit_transform(X).toarray())
# or 
pd.get_dummies(data[["color","price"]])
#+END_SRC

* Deep Learning
** Tensorflow
- install tensorflow:
#+BEGIN_SRC bash
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda install tensorflow-gpu==1.3
conda config --set show_channel_urls yes
conda install tensorflow-gpu==1.3
#+END_SRC
- test drive:
#+BEGIN_SRC bash
python -m tensorflow.models.image.mnist.convolutional
#+END_SRC
*** GPU test:
[[file:./tensorflow.py][tensorflow]]
#+INCLUDE: "tensorflow.py"
* NLP
** Keywords
#+BEGIN_SRC python
input_text_translations = """
The Chinese government’s top management obviously also hopes to avoid the deterioration of the Sino-US conflict. The Sino-US trade war has started. After the Sino-US trade war began, it emphasized that China has "five advantages" in the trade war. He stressed: "We must especially prevent Sino-US cooperation. Trade conflict spreads to the ideological field
"""
from gensim import corpora, models, similarities
from nltk.tokenize import word_tokenize, sent_tokenize
from sklearn import feature_extraction
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer

test_model = word_tokenize(input_text_translations.lower())

wordstest_model = sent_tokenize(input_text_translations)
test_model = [word_tokenize(_d.lower()) for _d in docs]
dictionary = corpora.Dictionary(test_model, prune_at=2000000)
# for key in dictionary.iterkeys():
#     print key,dictionary.get(key),dictionary.dfs[key]
corpus_model = [dictionary.doc2bow(test) for test in test_model]
tfidf_model = models.TfidfModel(corpus_model)
# 对语料生成tfidf
corpus_tfidf = tfidf_model[corpus_model]
d = {dictionary.get(id): value for doc in corpus_tfidf for id, value in doc}

#+END_SRC


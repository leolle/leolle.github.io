#+SETUPFILE: ../configOrg/level2.org
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline author:t c:nil
#+OPTIONS: creator:nil d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+OPTIONS: title:t toc:t todo:t |:t
#+TITLES: python2
#+DATE: <2017-05-24 Wed>
#+AUTHORS: weiwu
#+EMAIL: victor.wuv@gmail.com
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode 8.3.4)

* Basic operations:
- config file location:
/usr/share/elasticsearch/config/elasticsearch.yml

- 查看当前节点的所有 Index

#+BEGIN_SRC bash
curl -X GET 'http://localhost:9200/_cat/indices?v'
#+END_SRC

- test elasticsearch
#+BEGIN_SRC bash
curl localhost:9200
#+END_SRC

- 列出每个 Index 所包含的 Type
#+BEGIN_SRC bash
curl 'localhost:9200/_mapping?pretty=true'
#+END_SRC

- check index:
#+BEGIN_SRC bash
http://192.168.4.36:9200/beijin_icd_code_name
#+END_SRC

- 新建 Index
#+BEGIN_SRC bash
curl -X PUT 'localhost:9200/weather'
#+END_SRC

- 删除这个 Index
#+BEGIN_SRC bash
curl -X DELETE 'localhost:9200/weather'
#+END_SRC

- 新建一个 Index，指定需要分词的字段。
#+BEGIN_SRC bash
curl -X PUT 'localhost:9200/accounts' -d '
{
  "mappings": {
    "person": {
      "properties": {
        "user": {
          "type": "text",
          "analyzer": "ik_max_word",
          "search_analyzer": "ik_max_word"
        },
        "title": {
          "type": "text",
          "analyzer": "ik_max_word",
          "search_analyzer": "ik_max_word"
        },
        "desc": {
          "type": "text",
          "analyzer": "ik_max_word",
          "search_analyzer": "ik_max_word"
        }
      }
    }
  }
}'
#+END_SRC

- 新增记录
#+BEGIN_SRC bash
# 请求路径是/accounts/person/1，最后的1是该条记录的 Id
curl -X PUT 'localhost:9200/accounts/person/1' -d '
{
  "user": "张三",
  "title": "工程师",
  "desc": "数据库管理"
}'
#+END_SRC

- 查看记录
#+BEGIN_SRC bash
curl 'localhost:9200/accounts/person/1?pretty=true'
#+END_SRC

- search by id field:

#+BEGIN_SRC python
http://192.168.4.36:9200/test-vector-index/_source/44114
#+END_SRC

- 删除记录
#+BEGIN_SRC bash
curl -X DELETE 'localhost:9200/accounts/person/1'
#+END_SRC

- 更新记录
#+BEGIN_SRC bash
curl -X PUT 'localhost:9200/accounts/person/1' -d '
{
    "user" : "张三",
    "title" : "工程师",
    "desc" : "数据库管理，软件开发"
}'

{
  "_index":"accounts",
  "_type":"person",
  "_id":"1",
  "_version":2,
  "result":"updated",
  "_shards":{"total":2,"successful":1,"failed":0},
  "created":false
}
#+END_SRC

- 返回所有记录
#+BEGIN_SRC bash
curl 'localhost:9200/accounts/person/_search'
#+END_SRC

- 全文搜索
#+BEGIN_SRC bash
curl 'localhost:9200/accounts/person/_search'  -d '
{
  "query" : { "match" : { "desc" : "软件" }}
}'
#+END_SRC

- 多个搜索关键字
#+BEGIN_SRC bash
curl 'localhost:9200/accounts/person/_search'  -d '
{
  "query" : { "match" : { "desc" : "软件 系统" }}
}'
#+END_SRC

- search query
#+BEGIN_SRC bash
http://192.168.4.36:9200/yiduyun_operation_name/_search?pretty
http://192.168.4.36:9200/beijin_icd_code_name/_search?&pretty=true
http://192.168.4.36:9200/nation_icd_code_name/_search?q=足趾骨折&pretty=true&size=10
http://192.168.4.36:9200/test-vector-index-1/_search?q=entity:HIV&size=200&pretty
#+END_SRC

- check all index
#+BEGIN_SRC bash
http://192.168.4.36:9200/_cat/indices
#+END_SRC

-
#+BEGIN_SRC bash

#+END_SRC

-
#+BEGIN_SRC bash

#+END_SRC

* python连接es
#+BEGIN_SRC bash
  from elasticsearch_dsl.connections import connections
  es = connections.create_connection(ArticleType._doc_type.using)
  或者
  from elasticsearch_dsl.connections import connections
  es = connections.create_connection(hosts=["localhost"])
  或者原生态连接
  from elasticsearch import Elasticsearch
  client = Elasticsearch(hosts=["127.0.0.1"])

#+END_SRC

* 创建索引/定义mapping
#+BEGIN_SRC bash
from elasticsearch_dsl import DocType, Date, Nested, Boolean, \
analyzer, InnerObjectWrapper, Completion, Keyword, Text, Integer

from elasticsearch_dsl.analysis import CustomAnalyzer as _CustomAnalyzer

from elasticsearch_dsl.connections import connections
connections.create_connection(hosts=["localhost"])

class CustomAnalyzer(_CustomAnalyzer):
    def get_analysis_definition(self):
        return {}


ik_analyzer = CustomAnalyzer("ik_max_word", filter=["lowercase"])

class ArticleType(DocType):
    #伯乐在线文章类型
    suggest = Completion(analyzer=ik_analyzer)
    title = Text(analyzer="ik_max_word")
    create_date = Date()
    url = Keyword()
    url_object_id = Keyword()
    front_image_url = Keyword()
    front_image_path = Keyword()
    praise_nums = Integer()
    comment_nums = Integer()
    fav_nums = Integer()
    tags = Text(analyzer="ik_max_word")
    content = Text(analyzer="ik_max_word")

    class Meta:
        index = "jobbole"
        doc_type = "article"

if __name__ == "__main__":
    ArticleType.init()
#+END_SRC


* analyze接口
#+BEGIN_SRC bash
  words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter':["lowercase"]}, body=text)
  #相当于kibana里使用如下命令
  GET _analyze
  {
      "analyzer": "ik_max_word",
      "text": text
   }

#+END_SRC

* suggest接口
#+BEGIN_SRC bash
   s = ArticleType.search()
   s = s.suggest('my_suggest', key_words, completion={
            "field":"suggest",
            "fuzzy":{ "fuzziness":2 },
            "size":10
        })
   suggestions = s.execute_suggest()
   对应kibana：
   POST music/_search
   {
    "suggest": {
        "my_suggest" : {
            "prefix" : key_words,
            "completion" : {
                "field" : "suggest" ,
                "fuzzy":{ "fuzziness":2 },
                "size":10
            }
        }
      }
    }
#+END_SRC


* search接口
#+BEGIN_SRC bash
  elaticsearch原生接口，跟kibana差不多
          response = client.search(
            index= "jobbole",
            body={
                "query":{
                    "multi_match":{
                        "query":key_words,
                        "fields":["tags", "title", "content"]
                    }
                },
                "from":(page-1)*10,
                "size":10,
                "highlight": {
                    "pre_tags": ['<span class="keyWord">'],
                    "post_tags": ['</span>'],
                    "fields": {
                        "title": {},
                        "content": {},
                    }
                }
            }
        )
    相当于kibana：
    GET jobbole/_search
   {
     "query":{
         "multi_match":{
            "query":key_words,
            "fields":["tags", "title", "content"]
          }
     },
     "from":0,
     "size":10,
     "highlight": {
         "pre_tags": ["<span class='linux'>"],
         "post_tags": ["</span>"],
         "fields": {
             "title": {},
             "content": {}
         }
     }
   }
#+END_SRC

* search

** 过滤情况（filtering context）和查询情况（query context）。

   Elasticsearch 使用的查询语言（DSL）拥有一套查询组件，这些组件可以以无限组合的方式进行搭配。这套组件可以在两种情况下使用.

   当使用于 过滤情况 时，查询被设置成一个“不评分”或者“过滤”查询。即，这个查询只是简单的问一个问题：“这篇文档是否匹配？”。回答也是非常的简单，yes 或者 no ，二者必居其一。

- created 时间是否在 2013 与 2014 这个区间？
- status 字段是否包含 published 这个单词？
- lat_lon 字段表示的位置是否在指定点的 10km 范围内？

当使用于 查询情况 时，查询就变成了一个“评分”的查询。和不评分的查询类似，也要去判断这个文档是否匹配，同时它还需要判断这个文档匹配的有 多好（匹配程度如何）。 此查询的典型用法是用于查找以下文档：

查找与 full text search 这个词语最佳匹配的文档
- 包含 run 这个词，也能匹配 runs 、 running 、 jog 或者 sprint
- 包含 quick 、 brown 和 fox 这几个词  词之间离的越近，文档相关性越高
- 标有 lucene 、 search 或者 java 标签  标签越多，相关性越高

一个评分查询计算每一个文档与此查询的 相关程度，同时将这个相关程度分配给表示相关性的字段 _score，并且按照相关性对匹配到的文档进行排序。这种相关性的概念是非常适合全文搜索的情况，因为全文搜索几乎没有完全 “正确” 的答案。

过滤查询（Filtering queries）只是简单的检查包含或者排除，这就使得计算起来非常快。考虑到至少有一个过滤查询（filtering query）的结果是 “稀少的”（很少匹配的文档），并且经常使用不评分查询（non-scoring queries），结果会被缓存到内存中以便快速读取，所以有各种各样的手段来优化查询结果。

相反，评分查询（scoring queries）不仅仅要找出匹配的文档，还要计算每个匹配文档的相关性，计算相关性使得它们比不评分查询费力的多。同时，查询结果并不缓存。

** query by vector:
- vector
#+BEGIN_SRC python
resp = es.search(index='test-vector-index', body={
     "_source": ["entity"],
     "query": {
         "script_score": {
             "query": {
                 "match_all": {}
             },
             "script": {
                 "source": "cosineSimilarity(params.queryVector, doc['entity_vector'])",
                 "params": {
                     "queryVector": input_vector
                 }
             }
         }
     }
 })
#+END
